{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Code Bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/t/tiendat.ng.cs/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_1d(vector1, vector2):\n",
    "    assert(len(vector1.shape) == 1)\n",
    "    assert(len(vector2.shape) == 1)\n",
    "    assert(vector1.shape[0] == vector2.shape[0])\n",
    "    return np.dot(vector1,vector2)/(norm(vector1)*norm(vector2))\n",
    "    \n",
    "    # return 1 - cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_3d_to_2d(vector):\n",
    "    assert(len(vector.shape) == 3)\n",
    "    first_dim = vector.shape[0]\n",
    "    second_dim = vector.shape[1]\n",
    "    new_dim = first_dim * second_dim\n",
    "    return vector.reshape(new_dim, vector.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_matrix_3d(vector1, vector2):\n",
    "    if (vector1 is None or vector2 is None):\n",
    "        return\n",
    "    assert(len(vector1.shape) == 3)\n",
    "    assert(len(vector2.shape) == 3)\n",
    "    # assert(vector1.shape[1] == vector2.shape[1])\n",
    "    # assert(vector1.shape[2] == vector2.shape[2])\n",
    "    vec1_2d = reshape_3d_to_2d(vector1)\n",
    "    vec2_2d = reshape_3d_to_2d(vector2)\n",
    "    M = vec1_2d.shape[0]\n",
    "    N = vec2_2d.shape[0]\n",
    "    similarity_scores = np.zeros((M, N))\n",
    "    # for m in range(M):\n",
    "    #     v = vec1_2d[m]\n",
    "    #     for n in range(m+1, N):\n",
    "    #         if (similarity_scores[m, n] != 0): continue\n",
    "    #         u = vec2_2d[n]\n",
    "    #         sim_score = np.dot(v,u)/(norm(v)*norm(u))\n",
    "    #         similarity_scores[m, n] = sim_score\n",
    "            \n",
    "    # for n in range(N):\n",
    "    #     u = vec2_2d[n]\n",
    "    #     for m in range(n+1, M):\n",
    "    #         if (similarity_scores[m, n] != 0): continue\n",
    "    #         v = vec1_2d[m]\n",
    "    #         sim_score = np.dot(v,u)/(norm(v)*norm(u))\n",
    "    #         similarity_scores[m, n] = sim_score\n",
    "    \n",
    "    for m in range(M):\n",
    "        v = vec1_2d[m]\n",
    "        for n in range(N):\n",
    "            if (similarity_scores[m, n] != 0): continue\n",
    "            u = vec2_2d[n]\n",
    "            sim_score = np.dot(v,u)/(norm(v)*norm(u))\n",
    "            similarity_scores[m, n] = sim_score\n",
    "\n",
    "    # np.savez(file_path, similarity_scores)\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_ids_single(text, tokenizer):\n",
    "    tokens        = tokenizer.tokenize(text)\n",
    "    print(tokens)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens) + [3]\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \\\n",
    "\"\"\"def get_max(my_list):\n",
    "if not my_list:\n",
    "    raise ValueError(\"Input list is empty\")\n",
    "\n",
    "max_element = max(my_list)\n",
    "return max_element\n",
    "\"\"\"\n",
    "\n",
    "text2 = \\\n",
    "\"\"\"def get_largest_value(L):\n",
    "largest = L[0]\n",
    "for element in L:\n",
    "    if element > largest:\n",
    "        largest = element\n",
    "return largest\"\"\"\n",
    "\n",
    "text3 = \\\n",
    "\"\"\"def m(L):\n",
    "    t = 0\n",
    "    c = 0\n",
    "    for e in L:\n",
    "        t += e\n",
    "        c += 1\n",
    "    return t/c\"\"\"\n",
    "    \n",
    "text4 = \\\n",
    "\"\"\"int getMaxValue(const int arr[], int size) {\n",
    "    if (size <= 0) {\n",
    "        // Handle empty array or invalid size\n",
    "        std::cerr << \"Invalid array size or empty array.\" << std::endl;\n",
    "        return -1; // You can choose a suitable default value or throw an exception\n",
    "    }\n",
    "\n",
    "    int max_value = arr[0]; // Assume the first element is the maximum\n",
    "\n",
    "    for (int i = 1; i < size; ++i) {\n",
    "        if (arr[i] > max_value) {\n",
    "            // Update max_value if a larger element is found\n",
    "            max_value = arr[i];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return max_value;\n",
    "}\"\"\"\n",
    "\n",
    "text5 = \\\n",
    "\"\"\"int getLastValue(const int arr[], int size) {\n",
    "    if (size <= 0) {\n",
    "        // Handle empty array or invalid size\n",
    "        std::cerr << \"Invalid array size or empty array.\" << std::endl;\n",
    "        return -1; // You can choose a suitable default value or throw an exception\n",
    "    }\n",
    "\n",
    "    return arr[size - 1];\n",
    "}\"\"\"\n",
    "\n",
    "text_desc1 = \"return max value of a list\"\n",
    "text_desc2 = \"return average value of a list\"\n",
    "\n",
    "sentences = [text1, text2, text3, text4, text5, text_desc1, text_desc2]\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    # encode each sentence and append to dictionary\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "    \n",
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_desc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m text2_tokens        \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mcls_token] \u001b[39m+\u001b[39m tokenizer\u001b[39m.\u001b[39mtokenize(text2)     \u001b[39m+\u001b[39m [tokenizer\u001b[39m.\u001b[39msep_token]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m text3_tokens        \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mcls_token] \u001b[39m+\u001b[39m tokenizer\u001b[39m.\u001b[39mtokenize(text3)     \u001b[39m+\u001b[39m [tokenizer\u001b[39m.\u001b[39msep_token]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m text_desc_tokens    \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mcls_token] \u001b[39m+\u001b[39m tokenizer\u001b[39m.\u001b[39mtokenize(text_desc) \u001b[39m+\u001b[39m [tokenizer\u001b[39m.\u001b[39msep_token]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_desc' is not defined"
     ]
    }
   ],
   "source": [
    "text1_tokens        = [tokenizer.cls_token] + tokenizer.tokenize(text1)     + [tokenizer.sep_token]\n",
    "text2_tokens        = [tokenizer.cls_token] + tokenizer.tokenize(text2)     + [tokenizer.sep_token]\n",
    "text3_tokens        = [tokenizer.cls_token] + tokenizer.tokenize(text3)     + [tokenizer.sep_token]\n",
    "text_desc_tokens    = [tokenizer.cls_token] + tokenizer.tokenize(text_desc) + [tokenizer.sep_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_desc_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m text2_token_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_tokens_to_ids(text2_tokens)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m text3_token_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_tokens_to_ids(text3_tokens)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m text_desc_token_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_tokens_to_ids(text_desc_tokens)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_desc_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "text1_token_ids = tokenizer.convert_tokens_to_ids(text1_tokens)\n",
    "text2_token_ids = tokenizer.convert_tokens_to_ids(text2_tokens)\n",
    "text3_token_ids = tokenizer.convert_tokens_to_ids(text3_tokens)\n",
    "text_desc_token_ids = tokenizer.convert_tokens_to_ids(text_desc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0985,  0.2084, -0.0147,  ..., -0.2358, -0.3665,  0.3596],\n",
       "          [-1.1312, -0.1249,  0.5453,  ..., -1.1168, -0.2118,  0.5683],\n",
       "          [-0.5733,  0.0711,  0.1152,  ..., -0.1341, -0.1191,  0.8507],\n",
       "          ...,\n",
       "          [-0.3762, -0.1106,  0.4930,  ..., -0.5234,  0.0261,  0.0174],\n",
       "          [-0.3762, -0.1106,  0.4930,  ..., -0.5234,  0.0261,  0.0174],\n",
       "          [-0.3762, -0.1106,  0.4930,  ..., -0.5234,  0.0261,  0.0174]],\n",
       " \n",
       "         [[-0.1703,  0.1046, -0.0596,  ..., -0.2995, -0.4340,  0.4011],\n",
       "          [-0.9838,  0.1748,  0.4807,  ..., -1.1601, -0.1933,  0.6104],\n",
       "          [-0.6993,  0.2367,  0.3774,  ..., -0.4023, -0.1533,  0.7596],\n",
       "          ...,\n",
       "          [-0.3447,  0.2819,  0.3316,  ..., -0.6630, -0.0595,  0.3459],\n",
       "          [-0.3447,  0.2819,  0.3316,  ..., -0.6630, -0.0595,  0.3459],\n",
       "          [-0.3447,  0.2819,  0.3316,  ..., -0.6630, -0.0595,  0.3459]],\n",
       " \n",
       "         [[-0.2545,  0.0844, -0.0706,  ..., -0.3226, -0.5346,  0.5019],\n",
       "          [-1.1956, -0.0283,  0.6454,  ..., -1.0599, -0.2560,  0.3414],\n",
       "          [-0.8426, -0.2332,  0.1230,  ...,  0.2431, -0.5905,  0.3251],\n",
       "          ...,\n",
       "          [-0.1101,  0.0363,  0.4280,  ..., -0.7226, -0.0064,  0.2034],\n",
       "          [-0.1101,  0.0363,  0.4280,  ..., -0.7226, -0.0064,  0.2034],\n",
       "          [-0.1101,  0.0363,  0.4280,  ..., -0.7226, -0.0064,  0.2034]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0294,  0.1154, -0.1033,  ..., -0.0153, -0.5497,  0.5011],\n",
       "          [-0.1764, -0.4202, -0.0733,  ..., -0.3716, -0.3716,  1.1352],\n",
       "          [-0.5795, -0.0651,  0.1384,  ...,  0.1101, -0.3468,  0.6306],\n",
       "          ...,\n",
       "          [ 0.0816, -0.0477,  0.0888,  ...,  0.1014, -0.6649,  0.4885],\n",
       "          [ 0.0816, -0.0477,  0.0888,  ...,  0.1014, -0.6649,  0.4885],\n",
       "          [ 0.0816, -0.0477,  0.0888,  ...,  0.1014, -0.6649,  0.4885]],\n",
       " \n",
       "         [[-0.0405,  0.3229, -0.0172,  ..., -0.1317, -0.2965,  0.3332],\n",
       "          [-0.3324,  0.0605,  0.2990,  ...,  0.1805, -0.2667,  0.3129],\n",
       "          [-0.3456,  0.2490,  0.0116,  ..., -0.3521, -0.7611,  0.6918],\n",
       "          ...,\n",
       "          [ 0.3931,  0.2925,  0.0788,  ...,  0.0501, -0.2760,  0.5861],\n",
       "          [ 0.3931,  0.2925,  0.0788,  ...,  0.0501, -0.2760,  0.5861],\n",
       "          [ 0.3931,  0.2925,  0.0788,  ...,  0.0501, -0.2760,  0.5861]],\n",
       " \n",
       "         [[-0.0222,  0.3269, -0.0139,  ..., -0.1357, -0.2814,  0.3070],\n",
       "          [-0.3159, -0.0206,  0.2717,  ...,  0.1283, -0.2631,  0.2780],\n",
       "          [ 0.0064,  0.1655,  0.2523,  ..., -0.2687, -0.4247,  0.2280],\n",
       "          ...,\n",
       "          [ 0.2783,  0.1638,  0.0174,  ...,  0.1083, -0.3115,  0.5072],\n",
       "          [ 0.2783,  0.1638,  0.0174,  ...,  0.1083, -0.3115,  0.5072],\n",
       "          [ 0.2783,  0.1638,  0.0174,  ...,  0.1083, -0.3115,  0.5072]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[ 0.4338, -0.4412, -0.5427,  ..., -0.0782, -0.0323,  0.0691],\n",
       "         [ 0.4922, -0.4938, -0.6132,  ..., -0.0984, -0.0612,  0.1057],\n",
       "         [ 0.5133, -0.5125, -0.6329,  ..., -0.0957, -0.0572,  0.1008],\n",
       "         ...,\n",
       "         [ 0.5208, -0.5359, -0.6350,  ..., -0.1549, -0.0278,  0.1919],\n",
       "         [ 0.3809, -0.4155, -0.5073,  ..., -0.0204, -0.0102,  0.0170],\n",
       "         [ 0.3735, -0.4198, -0.5131,  ..., -0.0330, -0.0117,  0.0128]],\n",
       "        grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0985,  0.2084, -0.0147,  ..., -0.2358, -0.3665,  0.3596],\n",
       "         [-1.1312, -0.1249,  0.5453,  ..., -1.1168, -0.2118,  0.5683],\n",
       "         [-0.5733,  0.0711,  0.1152,  ..., -0.1341, -0.1191,  0.8507],\n",
       "         ...,\n",
       "         [-0.3762, -0.1106,  0.4930,  ..., -0.5234,  0.0261,  0.0174],\n",
       "         [-0.3762, -0.1106,  0.4930,  ..., -0.5234,  0.0261,  0.0174],\n",
       "         [-0.3762, -0.1106,  0.4930,  ..., -0.5234,  0.0261,  0.0174]],\n",
       "\n",
       "        [[-0.1703,  0.1046, -0.0596,  ..., -0.2995, -0.4340,  0.4011],\n",
       "         [-0.9838,  0.1748,  0.4807,  ..., -1.1601, -0.1933,  0.6104],\n",
       "         [-0.6993,  0.2367,  0.3774,  ..., -0.4023, -0.1533,  0.7596],\n",
       "         ...,\n",
       "         [-0.3447,  0.2819,  0.3316,  ..., -0.6630, -0.0595,  0.3459],\n",
       "         [-0.3447,  0.2819,  0.3316,  ..., -0.6630, -0.0595,  0.3459],\n",
       "         [-0.3447,  0.2819,  0.3316,  ..., -0.6630, -0.0595,  0.3459]],\n",
       "\n",
       "        [[-0.2545,  0.0844, -0.0706,  ..., -0.3226, -0.5346,  0.5019],\n",
       "         [-1.1956, -0.0283,  0.6454,  ..., -1.0599, -0.2560,  0.3414],\n",
       "         [-0.8426, -0.2332,  0.1230,  ...,  0.2431, -0.5905,  0.3251],\n",
       "         ...,\n",
       "         [-0.1101,  0.0363,  0.4280,  ..., -0.7226, -0.0064,  0.2034],\n",
       "         [-0.1101,  0.0363,  0.4280,  ..., -0.7226, -0.0064,  0.2034],\n",
       "         [-0.1101,  0.0363,  0.4280,  ..., -0.7226, -0.0064,  0.2034]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0294,  0.1154, -0.1033,  ..., -0.0153, -0.5497,  0.5011],\n",
       "         [-0.1764, -0.4202, -0.0733,  ..., -0.3716, -0.3716,  1.1352],\n",
       "         [-0.5795, -0.0651,  0.1384,  ...,  0.1101, -0.3468,  0.6306],\n",
       "         ...,\n",
       "         [ 0.0816, -0.0477,  0.0888,  ...,  0.1014, -0.6649,  0.4885],\n",
       "         [ 0.0816, -0.0477,  0.0888,  ...,  0.1014, -0.6649,  0.4885],\n",
       "         [ 0.0816, -0.0477,  0.0888,  ...,  0.1014, -0.6649,  0.4885]],\n",
       "\n",
       "        [[-0.0405,  0.3229, -0.0172,  ..., -0.1317, -0.2965,  0.3332],\n",
       "         [-0.3324,  0.0605,  0.2990,  ...,  0.1805, -0.2667,  0.3129],\n",
       "         [-0.3456,  0.2490,  0.0116,  ..., -0.3521, -0.7611,  0.6918],\n",
       "         ...,\n",
       "         [ 0.3931,  0.2925,  0.0788,  ...,  0.0501, -0.2760,  0.5861],\n",
       "         [ 0.3931,  0.2925,  0.0788,  ...,  0.0501, -0.2760,  0.5861],\n",
       "         [ 0.3931,  0.2925,  0.0788,  ...,  0.0501, -0.2760,  0.5861]],\n",
       "\n",
       "        [[-0.0222,  0.3269, -0.0139,  ..., -0.1357, -0.2814,  0.3070],\n",
       "         [-0.3159, -0.0206,  0.2717,  ...,  0.1283, -0.2631,  0.2780],\n",
       "         [ 0.0064,  0.1655,  0.2523,  ..., -0.2687, -0.4247,  0.2280],\n",
       "         ...,\n",
       "         [ 0.2783,  0.1638,  0.0174,  ...,  0.1083, -0.3115,  0.5072],\n",
       "         [ 0.2783,  0.1638,  0.0174,  ...,  0.1083, -0.3115,  0.5072],\n",
       "         [ 0.2783,  0.1638,  0.0174,  ...,  0.1083, -0.3115,  0.5072]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs[0]\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128, 768])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text1_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m text1_embedding\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text1_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "text1_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128, 768])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128, 768])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0985,  0.2084, -0.0147,  ..., -0.2358, -0.3665,  0.3596],\n",
       "         [-1.1312, -0.1249,  0.5453,  ..., -1.1168, -0.2118,  0.5683],\n",
       "         [-0.5733,  0.0711,  0.1152,  ..., -0.1341, -0.1191,  0.8507],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1703,  0.1046, -0.0596,  ..., -0.2995, -0.4340,  0.4011],\n",
       "         [-0.9838,  0.1748,  0.4807,  ..., -1.1601, -0.1933,  0.6104],\n",
       "         [-0.6993,  0.2367,  0.3774,  ..., -0.4023, -0.1533,  0.7596],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.2545,  0.0844, -0.0706,  ..., -0.3226, -0.5346,  0.5019],\n",
       "         [-1.1956, -0.0283,  0.6454,  ..., -1.0599, -0.2560,  0.3414],\n",
       "         [-0.8426, -0.2332,  0.1230,  ...,  0.2431, -0.5905,  0.3251],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0294,  0.1154, -0.1033,  ..., -0.0153, -0.5497,  0.5011],\n",
       "         [-0.1764, -0.4202, -0.0733,  ..., -0.3716, -0.3716,  1.1352],\n",
       "         [-0.5795, -0.0651,  0.1384,  ...,  0.1101, -0.3468,  0.6306],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0405,  0.3229, -0.0172,  ..., -0.1317, -0.2965,  0.3332],\n",
       "         [-0.3324,  0.0605,  0.2990,  ...,  0.1805, -0.2667,  0.3129],\n",
       "         [-0.3456,  0.2490,  0.0116,  ..., -0.3521, -0.7611,  0.6918],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0222,  0.3269, -0.0139,  ..., -0.1357, -0.2814,  0.3070],\n",
       "         [-0.3159, -0.0206,  0.2717,  ...,  0.1283, -0.2631,  0.2780],\n",
       "         [ 0.0064,  0.1655,  0.2523,  ..., -0.2687, -0.4247,  0.2280],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4235,  0.2881,  0.2646,  ..., -0.6353, -0.4293,  0.6803],\n",
       "        [-0.3458,  0.1308,  0.2953,  ..., -0.5086, -0.4853,  0.6119],\n",
       "        [-0.2817,  0.0571,  0.2189,  ..., -0.4147, -0.5097,  0.5551],\n",
       "        ...,\n",
       "        [-0.2065, -0.0235,  0.2284,  ..., -0.3111, -0.4478,  0.6506],\n",
       "        [-0.0564,  0.1062, -0.0027,  ...,  0.0219, -0.4743,  0.5632],\n",
       "        [ 0.0213,  0.1191, -0.0118,  ...,  0.0435, -0.4385,  0.4762]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed / summed_mask\n",
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = mean_pooled.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 768)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98526657"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9517823"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97757465"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[1], mean_pooled[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9414042"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504929"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88987374"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8784212"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504929"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(mean_pooled[0], mean_pooled[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_mean_embedding = np.mean(text1_embedding.detach().numpy()[0], axis=0)\n",
    "text2_mean_embedding = np.mean(text2_embedding.detach().numpy()[0], axis=0)\n",
    "text3_mean_embedding = np.mean(text3_embedding.detach().numpy()[0], axis=0)\n",
    "text_desc_mean_embedding = np.mean(text_desc_embedding.detach().numpy()[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98526657"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(text1_mean_embedding, text2_mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878421"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(text1_mean_embedding, text_desc_mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95178217"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(text1_mean_embedding, text3_mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89263886"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(text_desc_mean_embedding, text3_mean_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out one tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://peaceful0907.medium.com/sentence-embedding-by-bert-and-sentence-similarity-759f7beccbf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_classifier(nn.Module):\n",
    "    def __init__(self, bertmodel, num_label):\n",
    "        super(BERT_classifier, self).__init__()\n",
    "        self.bertmodel = bertmodel\n",
    "        self.classifier = nn.Linear(bertmodel.config.hidden_size, num_label)\n",
    "\n",
    "    def forward(self, wrapped_input):\n",
    "        hidden = self.bertmodel(**wrapped_input)\n",
    "        last_hidden_state, pooler_output = hidden[0], hidden[1]\n",
    "        logits = self.classifier(pooler_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "bert = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = BERT_classifier(bert, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_wrapped_input = tokenizer(text1, max_length=15, add_special_tokens=True, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "text2_wrapped_input = tokenizer(text2, max_length=15, add_special_tokens=True, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "text3_wrapped_input = tokenizer(text3, max_length=15, add_special_tokens=True, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "text_desc_wrapped_input = tokenizer(text_desc, max_length=15, add_special_tokens=True, truncation=True, padding='max_length', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_pair_tokens        = [tokenizer.cls_token] + tokenizer.tokenize(text_desc) + [tokenizer.sep_token] + tokenizer.tokenize(text1) + [tokenizer.eos_token]\n",
    "text2_pair_tokens        = [tokenizer.cls_token] + tokenizer.tokenize(text_desc) + [tokenizer.sep_token] + tokenizer.tokenize(text2) + [tokenizer.eos_token]\n",
    "text3_pair_tokens        = [tokenizer.cls_token] + tokenizer.tokenize(text_desc) + [tokenizer.sep_token] + tokenizer.tokenize(text3) + [tokenizer.eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_pair_token_ids = tokenizer.convert_tokens_to_ids(text1_pair_tokens)\n",
    "text2_pair_token_ids = tokenizer.convert_tokens_to_ids(text2_pair_tokens)\n",
    "text3_pair_token_ids = tokenizer.convert_tokens_to_ids(text3_pair_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_pair_embedding = model(torch.tensor(text1_pair_token_ids)[None, :])[1]\n",
    "text2_pair_embedding = model(torch.tensor(text2_pair_token_ids)[None, :])[1]\n",
    "text3_pair_embedding = model(torch.tensor(text3_pair_token_ids)[None, :])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_pair_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008173173"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(text1_pair_embedding.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'SC', 'ode', 'Server']\n",
      "['v', 'sc', 'ode', 'Client']\n",
      "['dis', 'ney', 'land']\n",
      "['v', 'sc', 'ode', 'Server']\n"
     ]
    }
   ],
   "source": [
    "tids1 = get_token_ids_single(\"VSCodeServer\", tokenizer)\n",
    "tids2 = get_token_ids_single(\"vscodeClient\", tokenizer)\n",
    "tids3 = get_token_ids_single(\"disneyland\", tokenizer)\n",
    "tids4 = get_token_ids_single(\"vscodeServer\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_embedding1 = model(torch.tensor(tids1)[None, :])[0]\n",
    "context_embedding2 = model(torch.tensor(tids2)[None, :])[0]\n",
    "context_embedding3 = model(torch.tensor(tids3)[None, :])[0]\n",
    "context_embedding4 = model(torch.tensor(tids4)[None, :])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_vector1 = context_embedding1.detach().numpy()[:, 0, :]\n",
    "last_vector2 = context_embedding2.detach().numpy()[:, 0, :]\n",
    "last_vector3 = context_embedding3.detach().numpy()[:, 0, :]\n",
    "last_vector4 = context_embedding4.detach().numpy()[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992478"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(last_vector1[0], last_vector2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99790347"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(last_vector1[0], last_vector3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979418"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(last_vector2[0], last_vector3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix12 = similarity_score_matrix_3d(context_embedding1.detach().numpy(), context_embedding2.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix13 = similarity_score_matrix_3d(context_embedding1.detach().numpy(), context_embedding3.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix14 = similarity_score_matrix_3d(context_embedding1.detach().numpy(), context_embedding4.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99924779 0.56499153 0.62505573 0.57279372]\n",
      "[0.60644126 0.94427735 0.85539436 0.84050715]\n",
      "[0.64857978 0.8738116  0.95530665 0.87383288]\n",
      "[0.63928145 0.84324539 0.87390709 0.94365901]\n"
     ]
    }
   ],
   "source": [
    "for i in matrix12:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99790347 0.67630619 0.64278752]\n",
      "[0.60614669 0.83747607 0.81981283]\n",
      "[0.6461795  0.86878538 0.8575666 ]\n",
      "[0.63783824 0.89322299 0.89370477]\n"
     ]
    }
   ],
   "source": [
    "for i in matrix13:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99945617 0.58030516 0.62634778 0.6110518 ]\n",
      "[0.60835147 0.94942743 0.8691678  0.86020535]\n",
      "[0.6508556  0.86774838 0.96582645 0.89685947]\n",
      "[0.6420384  0.85281646 0.8901177  0.98410237]\n"
     ]
    }
   ],
   "source": [
    "for i in matrix14:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912707962095737"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix12.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814775208632151"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix13.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8034173622727394"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix14.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1410906 ,  0.3659888 ,  0.04457453, -0.04732981,  0.04115221,\n",
       "       -0.19793634, -0.08595254,  0.01691525,  0.07735952, -0.07030746],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_vector1[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11602467,  0.37414128,  0.04851544, -0.05977523,  0.04996986,\n",
       "       -0.18897107, -0.10482092,  0.0216094 ,  0.0481642 , -0.12973918],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_vector3[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.088388"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(last_vector1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.934418"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(last_vector3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids1_embedding = model(torch.tensor(tids1)[None, :])[0]\n",
    "tids2_embedding = model(torch.tensor(tids2)[None, :])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1411,  0.3660,  0.0446,  ..., -0.2033, -0.3209,  0.3346],\n",
       "         [-0.3140,  0.5784,  0.4030,  ...,  0.3538, -0.5442,  0.3591],\n",
       "         [-0.3408,  0.6607,  0.1974,  ..., -0.3252, -0.3707,  0.4559],\n",
       "         [-0.3417,  0.1081, -0.1175,  ..., -0.0371, -0.4847,  0.1521],\n",
       "         [-0.0482,  0.2290,  0.0767,  ..., -0.1025, -0.6494,  0.4877],\n",
       "         [-0.1407,  0.3658,  0.0450,  ..., -0.2029, -0.3208,  0.3339]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tids1_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1075,  0.3750,  0.0401,  ..., -0.1878, -0.3041,  0.3191],\n",
       "         [-0.2476,  0.4381,  0.1267,  ..., -0.5965, -0.4729,  0.1755],\n",
       "         [-0.1068,  0.3740,  0.0405,  ..., -0.1877, -0.3029,  0.3171]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tids2_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reshape_3d_to_2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb Cell 60\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m similarity_score_matrix_3d(tids1_embedding, tids2_embedding)\n",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb Cell 60\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(vector2\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# assert(vector1.shape[1] == vector2.shape[1])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# assert(vector1.shape[2] == vector2.shape[2])\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m vec1_2d \u001b[39m=\u001b[39m reshape_3d_to_2d(vector1)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m vec2_2d \u001b[39m=\u001b[39m reshape_3d_to_2d(vector2)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/codeBert_sandbox.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m M \u001b[39m=\u001b[39m vec1_2d\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reshape_3d_to_2d' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_score_matrix_3d(tids1_embedding, tids2_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
