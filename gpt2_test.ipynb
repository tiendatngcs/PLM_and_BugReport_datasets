{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/t/tiendat.ng.cs/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "import sqlite3\n",
    "import argparse\n",
    "# from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download code Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.04M/1.04M [00:00<00:00, 5.42MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 880kB/s] \n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 329kB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [00:05<00:00, 105MB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')  # or any other checkpoint\n",
    "word_embeddings = model.transformer.wte.weight  # Word Token Embeddings \n",
    "position_embeddings = model.transformer.wpe.weight  # Word Position Embeddings \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = \"./dbrd_processed.db\"\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(database_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_names(conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch table names using SQL query\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    # Extract table names from the result\n",
    "    project_names = [table[0] for table in tables]\n",
    "    return project_names\n",
    "\n",
    "project_names = get_project_names(conn)\n",
    "column_names = ['bug_id',\n",
    "                'key',\n",
    "                'creation_ts',\n",
    "                'short_desc',\n",
    "                'product',\n",
    "                'component',\n",
    "                'version',\n",
    "                'bug_status',\n",
    "                'resolution',\n",
    "                'priority',\n",
    "                'bug_severity',\n",
    "                'description',\n",
    "                'code_feature',\n",
    "                'dup_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union-find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionFind:\n",
    "    def __init__(self):\n",
    "        self.parent = {}  # Dictionary to store parent nodes\n",
    "        self.ranks = {}    # Dictionary to store rank (or size) of each set\n",
    "        self.processed = False\n",
    "\n",
    "    def find(self, x):\n",
    "        if x not in self.parent:\n",
    "            self.parent[x] = x\n",
    "            self.ranks[x] = 1\n",
    "            return x\n",
    "\n",
    "        # Path compression\n",
    "        if self.parent[x] != x:\n",
    "            self.parent[x] = self.find(self.parent[x])\n",
    "        return self.parent[x]\n",
    "\n",
    "    def union(self, x, y):\n",
    "        root_x = self.find(x)\n",
    "        root_y = self.find(y)\n",
    "\n",
    "        if root_x != root_y:\n",
    "            if self.ranks[root_x] < self.ranks[root_y]:\n",
    "                self.parent[root_x] = root_y\n",
    "                self.ranks[root_y] += self.ranks[root_x]\n",
    "            else:\n",
    "                self.parent[root_y] = root_x\n",
    "                self.ranks[root_x] += self.ranks[root_y]\n",
    "            \n",
    "    def process_project(self, conn, project_name):\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(f\"SELECT * FROM {project_name}\")\n",
    "        for row in cursor.fetchall():\n",
    "            dup_id = int(row[column_names.index(\"dup_id\")])\n",
    "            if dup_id == -1: continue\n",
    "            bug_id = int(row[column_names.index(\"bug_id\")])\n",
    "            assert(dup_id != bug_id)\n",
    "            self.union(bug_id, dup_id)\n",
    "        self.processed = True\n",
    "            \n",
    "    def get_roots(self,):\n",
    "        assert(self.processed)\n",
    "        return list(set(self.parent.values()))\n",
    "    \n",
    "    def get_children(self, parent):\n",
    "        assert(self.processed)\n",
    "        parent = self.find(parent)\n",
    "        children = [key for key, value in self.parent.items() if value == parent]\n",
    "        return children\n",
    "    \n",
    "    def are_dups(this, bug_id1, bug_id2):\n",
    "        return this.parent[bug_id1] == this.parent[bug_id2]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bug_ids(conn, table_name):\n",
    "    cursor = conn.cursor()\n",
    "    column_name = \"bug_id\"\n",
    "\n",
    "    # Fetch table names using SQL query\n",
    "    cursor.execute(f\"SELECT DISTINCT {column_name} FROM {table_name} ORDER BY {column_name};\")\n",
    "    distinct_values_sorted = cursor.fetchall()\n",
    "\n",
    "    # Extract table names from the result\n",
    "    return [value[0] for value in distinct_values_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(description, stride_len, chunk_size):\n",
    "    tokens = tokenizer.tokenize(description)\n",
    "    # if len og token array is < 32, we do nothing as there is not enough information\n",
    "    if (len(tokens) < chunk_size // 2): return None\n",
    "\n",
    "    # remember to add cls and sep token at each chunk\n",
    "    token_ids = tokenizer.convert_tokens_to_ids([tokenizer.cls_token]+tokens+[tokenizer.sep_token])\n",
    "\n",
    "    # divide token ids into batche of chunks\n",
    "    chunk_list=[]\n",
    "    for i in range(0, len(token_ids), stride_len):\n",
    "        chunk = token_ids[i:min(i+chunk_size, len(token_ids))]\n",
    "        assert(len(chunk) <= chunk_size)\n",
    "        if len(chunk) < chunk_size:\n",
    "            # keep going\n",
    "            continue\n",
    "            # if (len(chunk) < chunk_size // 2): continue\n",
    "            # pad_length = chunk_size - len(chunk)\n",
    "            # chunk += [tokenizer.pad_token_id]*pad_length\n",
    "        assert(len(chunk) == chunk_size)\n",
    "        # print(chunk)\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    if(len(chunk_list) == 0): return None\n",
    "    chunk_arr = np.array(chunk_list)\n",
    "    # print(\"Chunk arr size{}\".format(chunk_arr.shape))\n",
    "    # context_embedding = model(torch.tensor(token_ids[:512])[None, :])[0]\n",
    "    context_embedding = model(torch.tensor(chunk_arr)[:, :])[0]\n",
    "    return context_embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptions(conn, project_name, bug_id):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch table names using SQL query\n",
    "    query = f\"SELECT * FROM {project_name} WHERE bug_id = {bug_id};\"\n",
    "    # print(query)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()[0]\n",
    "    desc = result[column_names.index(\"description\")]\n",
    "    short_desc = result[column_names.index(\"short_desc\")]\n",
    "\n",
    "    # Extract table names from the result\n",
    "    return (desc + \"\\n\" + short_desc).replace(\"\\\\'\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_feature(conn, project_name, bug_id):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fetch table names using SQL query\n",
    "    query = f\"SELECT * FROM {project_name} WHERE bug_id = {bug_id};\"\n",
    "    # print(query)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()[0]\n",
    "    code_feature = result[column_names.index(\"code_feature\")]\n",
    "\n",
    "    # Extract table names from the result\n",
    "    return code_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_1d(vector1, vector2):\n",
    "    assert(len(vector1.shape) == 1)\n",
    "    assert(len(vector2.shape) == 1)\n",
    "    assert(vector1.shape[0] == vector2.shape[0])\n",
    "    return np.dot(vector1,vector2)/(norm(vector1)*norm(vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_2d(vector1, vector2):\n",
    "    # print(vector1.shape)\n",
    "    # print(vector2.shape)\n",
    "    assert(len(vector1.shape) == 2)\n",
    "    assert(len(vector2.shape) == 2)\n",
    "    max_score = 0\n",
    "    min_score = sys.maxsize\n",
    "    total_score = 0\n",
    "    num_scores = 0\n",
    "    high_score_count = 0\n",
    "    for v in vector1:\n",
    "        for u in vector2:\n",
    "            sim_score = np.dot(v,u)/(norm(v)*norm(u))\n",
    "            if sim_score > max_score:\n",
    "                max_score = sim_score\n",
    "            if sim_score < min_score:\n",
    "                min_score = sim_score\n",
    "            total_score += sim_score\n",
    "            num_scores += 1\n",
    "            if sim_score > 0.99:\n",
    "                high_score_count += 1\n",
    "    return (max_score, min_score, total_score/num_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_3d_to_2d(vector):\n",
    "    assert(len(vector.shape) == 3)\n",
    "    first_dim = vector.shape[0]\n",
    "    second_dim = vector.shape[1]\n",
    "    new_dim = first_dim * second_dim\n",
    "    return vector.reshape(new_dim, vector.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score_3d(vector1, vector2):\n",
    "    assert(len(vector1.shape) == 3)\n",
    "    assert(len(vector2.shape) == 3)\n",
    "    assert(vector1.shape[1] == vector2.shape[1])\n",
    "    assert(vector1.shape[2] == vector2.shape[2])\n",
    "    vec1_2d = reshape_3d_to_2d(vector1)\n",
    "    vec2_2d = reshape_3d_to_2d(vector2)\n",
    "    score = similarity_score_2d(vec1_2d, vec2_2d)\n",
    "    return score\n",
    "    # max_score = 0\n",
    "    # min_score = sys.maxsize\n",
    "    # total_score = 0\n",
    "    # num_scores = 0\n",
    "    # for v in vector1:\n",
    "    #     for u in vector2:\n",
    "    #         sim_score = similarity_score_2d(u, v)\n",
    "    #         if sim_score[0] > max_score:\n",
    "    #             max_score = sim_score[0]\n",
    "    #         if sim_score[1] < min_score:\n",
    "    #             min_score = sim_score[1]\n",
    "    #         total_score += sim_score[2]\n",
    "    #         num_scores += 1\n",
    "    # return (max_score, min_score, total_score/num_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"spark\"\n",
    "\n",
    "bug_ids = get_bug_ids(conn, project_name)\n",
    "\n",
    "union_find = UnionFind()\n",
    "union_find.process_project(conn, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a table of scores\n",
    "Initialized with value -1\n",
    "If bug report is too short, all of its scores becomes -2\n",
    "Otherwise, must be updated to a value >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bug_ids = len(bug_ids)\n",
    "similarity_scores = np.ones((num_bug_ids, num_bug_ids)) * -1\n",
    "np.fill_diagonal(similarity_scores, -2)\n",
    "similarity_scores[np.tril_indices(len(similarity_scores), k=-1)] = -2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two nesting loop to go through each pair of combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM eclipse WHERE bug_id = 529329;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529330;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529331;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529332;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529334;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529335;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529337;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529338;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529339;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529341;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529342;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529343;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529344;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529345;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529346;\n",
      "SELECT * FROM eclipse WHERE bug_id = 529347;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27583 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb Cell 23\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m bug_id2 \u001b[39m=\u001b[39m bug_ids[j]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m desc2 \u001b[39m=\u001b[39m get_descriptions(conn, project_name, bug_id2)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m vector2 \u001b[39m=\u001b[39m vectorize(desc2, \u001b[39m64\u001b[39;49m, \u001b[39m128\u001b[39;49m)\n",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m chunk_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(chunk_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# print(\"Chunk arr size{}\".format(chunk_arr.shape))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# context_embedding = model(torch.tensor(token_ids[:512])[None, :])[0]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m context_embedding \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39;49mtensor(chunk_arr)[:, :])[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m context_embedding\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:732\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    727\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    729\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    730\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, token_type_ids\u001b[39m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds\n\u001b[1;32m    731\u001b[0m )\n\u001b[0;32m--> 732\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    733\u001b[0m     embedding_output,\n\u001b[1;32m    734\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    735\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    736\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    737\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    738\u001b[0m )\n\u001b[1;32m    739\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    740\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:407\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_hidden_states:\n\u001b[1;32m    405\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 407\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    408\u001b[0m     hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask\n\u001b[1;32m    409\u001b[0m )\n\u001b[1;32m    410\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:369\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    363\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    368\u001b[0m ):\n\u001b[0;32m--> 369\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(hidden_states, attention_mask, head_mask)\n\u001b[1;32m    370\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    371\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:314\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    313\u001b[0m ):\n\u001b[0;32m--> 314\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    315\u001b[0m         hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    318\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:242\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    239\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n\u001b[1;32m    241\u001b[0m \u001b[39m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mSoftmax(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)(attention_scores)\n\u001b[1;32m    244\u001b[0m \u001b[39m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py:1514\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1514\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msoftmax(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim, _stacklevel\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1855\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1856\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[1;32m   1857\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1858\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, num_bug_ids)):\n",
    "    bug_id1 = bug_ids[i]\n",
    "    desc1 = get_descriptions(conn, project_name, bug_id1)\n",
    "    vector1 = vectorize(desc1, 64, 128)\n",
    "    for j in range(i+1, num_bug_ids):\n",
    "        bug_id2 = bug_ids[j]\n",
    "        desc2 = get_descriptions(conn, project_name, bug_id2)\n",
    "        vector2 = vectorize(desc2, 64, 128)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1915/27583 [04:00<53:39,  7.97it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, num_bug_ids)):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     desc \u001b[39m=\u001b[39m get_descriptions(conn, project_name, bug_ids[i])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     vectorize(desc, \u001b[39m64\u001b[39;49m, \u001b[39m128\u001b[39;49m)\n",
      "\u001b[1;32m/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m chunk_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(chunk_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# print(\"Chunk arr size{}\".format(chunk_arr.shape))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# context_embedding = model(torch.tensor(token_ids[:512])[None, :])[0]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m context_embedding \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39;49mtensor(chunk_arr)[:, :])[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcsce-nguyen-s4.engr.tamu.edu/home/grads/t/tiendat.ng.cs/github_repos/BERTOverflow_test/code_bert_test.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m context_embedding\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:732\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    727\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    729\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    730\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, token_type_ids\u001b[39m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds\n\u001b[1;32m    731\u001b[0m )\n\u001b[0;32m--> 732\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    733\u001b[0m     embedding_output,\n\u001b[1;32m    734\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    735\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    736\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    737\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    738\u001b[0m )\n\u001b[1;32m    739\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    740\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:407\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_hidden_states:\n\u001b[1;32m    405\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 407\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    408\u001b[0m     hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask\n\u001b[1;32m    409\u001b[0m )\n\u001b[1;32m    410\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:369\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    363\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    368\u001b[0m ):\n\u001b[0;32m--> 369\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(hidden_states, attention_mask, head_mask)\n\u001b[1;32m    370\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    371\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:317\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    313\u001b[0m ):\n\u001b[1;32m    314\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    315\u001b[0m         hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m    318\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py:271\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, input_tensor):\n\u001b[1;32m    270\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 271\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[1;32m    272\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39m=\u001b[39m OrderedDict()\n\u001b[1;32m   1675\u001b[0m \u001b[39m# On the return type:\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[39m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[39m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[39m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[39m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m   1683\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1684\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, num_bug_ids)):\n",
    "    desc = get_descriptions(conn, project_name, bug_ids[i])\n",
    "    vectorize(desc, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27583/27583 [04:05<00:00, 112.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, num_bug_ids)):\n",
    "    #load vector from saved file\n",
    "    bug_id = bug_ids[i]\n",
    "    file_name = \"{}_{}.npz\".format(project_name, bug_id)\n",
    "    file_path = os.path.join(\"./vectorize\", project_name, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        array = np.load(file_path)['arr_0']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('./vectorize/eclipse/eclipse_529330.npz')\n",
    "array1 = loaded_data['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select set of reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spin up 8 threads to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector_from_file(folder_name, project_name, bug_id):\n",
    "    file_name = \"{}_{}.npz\".format(project_name, bug_id)\n",
    "    file_path = os.path.join(f\"./{folder_name}\", project_name, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        array = np.load(file_path)['arr_0']\n",
    "        return array\n",
    "    return None\n",
    "\n",
    "def file_exists(project_name, bug_id):\n",
    "    file_name = \"{}_{}.npz\".format(project_name, bug_id)\n",
    "    file_path = os.path.join(\"./vectorize\", project_name, file_name)\n",
    "    return os.path.exists(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n",
      "[13169540, 13145078]\n",
      "13288450\n"
     ]
    }
   ],
   "source": [
    "roots = union_find.get_roots()\n",
    "print(len(roots))\n",
    "print(union_find.get_children(13145078))\n",
    "\n",
    "for root in roots:\n",
    "    children = union_find.get_children(root)\n",
    "    if (len(children) < 2):\n",
    "        print(\"Root has only {} children\".format(len(children)))\n",
    "    assert(root in children)\n",
    "\n",
    "print(roots[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_list = []\n",
    "for root in roots[:len(roots)//2]:\n",
    "    children = union_find.get_children(root)\n",
    "    duplicated_list += children\n",
    "\n",
    "number_of_duplicated = len(duplicated_list)\n",
    "# nonduplicated_list = np.random.choice(bug_ids, number_of_duplicated).tolist()\n",
    "# nonduplicated_list = [id for id in nonduplicated_list if file_exists(project_name, id)]\n",
    "nonduplicated_list = []\n",
    "\n",
    "# selected_bug_ids = np.sort(np.array(list(set(duplicated_list + nonduplicated_list))))\n",
    "selected_bug_ids = np.sort(np.array(duplicated_list))\n",
    "\n",
    "assert(len(duplicated_list) == len(set(duplicated_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9579"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bug_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_bug_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_selected_bug_ids = len(selected_bug_ids)\n",
    "similarity_scores_avg = np.ones((num_selected_bug_ids, num_selected_bug_ids)) * -1\n",
    "np.fill_diagonal(similarity_scores_avg, -2)\n",
    "similarity_scores_avg[np.tril_indices(len(similarity_scores_avg), k=-1)] = -2\n",
    "\n",
    "\n",
    "similarity_scores_max = similarity_scores_avg.copy()\n",
    "similarity_scores_min = similarity_scores_avg.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(thread_id, num_threads, project_name):\n",
    "    # section_size = len(selected_bug_ids)\n",
    "    # if (num_threads != 1):\n",
    "    section_size = len(selected_bug_ids) // (num_threads)\n",
    "    start_index = thread_id\n",
    "    end_index = len(selected_bug_ids)\n",
    "    step = section_size\n",
    "    # database_path = \"./dbrd.db\"\n",
    "    # thread_conn = sqlite3.connect(database_path)\n",
    "    # thread_cursor = thread_conn.cursor()\n",
    "    # if (thread_id == 0):\n",
    "        # print(f\"Progress in {section_size} :\")\n",
    "    # with  tqdm(total=section_size*section_size//2, position=thread_id, desc=\"thread 0\") as progress:\n",
    "    for i in range(start_index, end_index, step):\n",
    "        print(\"{} | Thread {}: {}\".format(datetime.now(), thread_id, i))\n",
    "        # if (thread_id == 0):\n",
    "        #     current_time = datetime.now()\n",
    "\n",
    "        #     # Format and print the current time\n",
    "        #     formatted_time = current_time.strftime(\"%H:%M:%S\")  # HH:MM:SS format\n",
    "        #     print(\"Current time:\", formatted_time)\n",
    "        #     print(f\"{i}\", end=\" \")\n",
    "        # print(project_name)\n",
    "        # print(selected_bug_ids[i])\n",
    "        # desc1 = get_descriptions(thread_conn, project_name, selected_bug_ids[i])\n",
    "        # vec1 = vectorize(desc1, 1, 1)\n",
    "        vec1 = load_vector_from_file(project_name, selected_bug_ids[i])\n",
    "        assert(vec1.shape[1] == 1)\n",
    "        if vec1 is None:\n",
    "            for j in range(i, len(selected_bug_ids)):\n",
    "                similarity_scores[i, j] = -1\n",
    "            continue\n",
    "        vec1 = np.array([v[0] for v in vec1] )\n",
    "        for j in range(i+1, len(selected_bug_ids), 1):\n",
    "            if (thread_id == 0):\n",
    "                print(j, end=\" \")\n",
    "            #     progress.update(1)\n",
    "            # desc2 = get_descriptions(thread_conn, project_name, selected_bug_ids[j])\n",
    "            # vec2 = vectorize(desc2, 1, 1)\n",
    "            vec2 = load_vector_from_file(project_name, selected_bug_ids[j])\n",
    "            if vec2 is None:\n",
    "                similarity_scores[i, j] = -1\n",
    "                continue\n",
    "            \n",
    "            vec2 = np.array([v[0] for v in vec2] )\n",
    "            sim_score = similarity_score_2d(vec1, vec2)\n",
    "            similarity_scores_max[i, j] = sim_score[0]\n",
    "            similarity_scores_min[i, j] = sim_score[1]\n",
    "            similarity_scores_avg[i, j] = sim_score[2]\n",
    "        print(\"\\n\") \n",
    "    # thread_conn.close()      \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-09 04:13:27.369342 | Thread 0: 0\n",
      "2023-11-09 04:13:27.370936 | Thread 1: 1\n",
      "2023-11-09 04:13:27.371842 | Thread 2: 2\n",
      "2023-11-09 04:13:27.372539 | Thread 3: 3\n",
      "2023-11-09 04:13:27.372883 | Thread 4: 4\n",
      "2023-11-09 04:13:27.373461 | Thread 5: 5\n",
      "2023-11-09 04:13:27.374510 | Thread 6: 6\n",
      "2023-11-09 04:13:27.376462 | Thread 7: 7\n",
      "2023-11-09 04:13:27.378035 | Thread 8: 8\n",
      "2023-11-09 04:13:27.379368 | Thread 9: 9\n",
      "2023-11-09 04:13:27.380056 | Thread 10: 10\n",
      "2023-11-09 04:13:27.381664 | Thread 11: 11\n",
      "2023-11-09 04:13:27.382253 | Thread 12: 12\n",
      "2023-11-09 04:13:27.384191 | Thread 13: 13\n",
      "2023-11-09 04:13:27.386978 | Thread 14: 14\n",
      "2023-11-09 04:13:27.390020 | Thread 15: 15\n",
      "2023-11-09 04:13:27.390461 | Thread 16: 16\n",
      "2023-11-09 04:13:27.392846 | Thread 17: 17\n",
      "2023-11-09 04:13:27.397409 | Thread 18: 18\n",
      "2023-11-09 04:13:27.398520 | Thread 19: 19\n",
      "2023-11-09 04:13:27.401132 | Thread 20: 20\n",
      "2023-11-09 04:13:27.402350 | Thread 21: 21\n",
      "2023-11-09 04:13:27.405539 | Thread 22: 22\n",
      "2023-11-09 04:13:27.408167 | Thread 23: 23\n",
      "2023-11-09 04:13:27.411943 | Thread 24: 24\n",
      "2023-11-09 04:13:27.414460 | Thread 25: 25\n",
      "2023-11-09 04:13:27.416811 | Thread 26: 26\n",
      "2023-11-09 04:13:27.419470 | Thread 27: 27\n",
      "2023-11-09 04:13:27.421658 | Thread 28: 28\n",
      "2023-11-09 04:13:27.422417 | Thread 29: 29\n",
      "2023-11-09 04:13:27.428967 | Thread 30: 30\n",
      "2023-11-09 04:13:27.432872 | Thread 31: 31\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 "
     ]
    }
   ],
   "source": [
    "num_threads = 32\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    threads.append(threading.Thread(target=compute_similarity, args=(i, num_threads, project_name)))\n",
    "\n",
    "for i in range(num_threads):\n",
    "    threads[i].start()\n",
    "    \n",
    "\n",
    "for i in range(num_threads):\n",
    "    threads[i].join()\n",
    "    \n",
    "print(\"End threading\")\n",
    "np.savez(\"similarity_scores_avg\", similarity_scores_avg)\n",
    "np.savez(\"similarity_scores_min\", similarity_scores_min)\n",
    "np.savez(\"similarity_scores_max\", similarity_scores_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"similarity_scores_avg\", similarity_scores_avg)\n",
    "np.savez(\"similarity_scores_min\", similarity_scores_min)\n",
    "np.savez(\"similarity_scores_max\", similarity_scores_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM eclipse WHERE bug_id = 529329;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'your eclipse not running or working.please correct it.\\nyour eclipse not running or working.please correct it.'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_descriptions(conn, project_name, 529329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4249,)\n"
     ]
    }
   ],
   "source": [
    "print(selected_bug_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = load_vector_from_file(project_name, 13127845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 1, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13285890, 13254983]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_find.get_children(roots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = load_vector_from_file(project_name, 13285890)\n",
    "vec1 = np.array([v[0] for v in vec1])\n",
    "vec2 = load_vector_from_file(project_name, 13254983)\n",
    "vec2 = np.array([v[0] for v in vec2])\n",
    "\n",
    "vec3 = load_vector_from_file(project_name, 13128106)\n",
    "vec3 = np.array([v[0] for v in vec3])\n",
    "\n",
    "vec4 = load_vector_from_file(project_name, 13348337)\n",
    "vec4 = np.array([v[0] for v in vec4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002, 0.9999975, 0.9999995904810288)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002, 0.99999654, 0.9999997026108681)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vec1, vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999976"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_1d(vec1[0]*100, vec3[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.29971611e+00,  3.64062524e+00,  4.18271899e-01, -5.09180307e-01,\n",
       "        7.35545382e-02, -1.86309588e+00, -1.18745732e+00,  3.21368814e-01,\n",
       "        1.81408003e-01, -8.79562736e-01,  1.64674163e+00,  4.55390024e+00,\n",
       "       -1.50769413e+00,  9.27534625e-02,  2.49651861e+00,  1.63323134e-01,\n",
       "        7.56912231e-01,  8.71441960e-01,  4.40602243e-01,  8.08974266e-01,\n",
       "       -1.81185734e+00, -3.61422658e-01,  2.27963591e+00,  8.11176062e-01,\n",
       "        4.11778307e+00, -2.16141820e-01,  2.82783771e+00,  2.45873761e+00,\n",
       "        2.55602121e-01,  4.23319721e+00, -4.25843716e-01, -1.01510227e-01,\n",
       "        1.33462667e+01, -1.26651633e+00,  1.80204761e+00, -6.78412795e-01,\n",
       "       -1.81989133e-01,  2.87226677e+00, -1.35306430e+00,  2.04299420e-01,\n",
       "       -3.90289187e+00, -9.03382823e-02, -9.23968697e+00,  1.72763181e+00,\n",
       "        3.70866680e+00, -1.78383321e-01,  2.75372446e-01,  2.60811615e+00,\n",
       "       -9.57559347e-01,  1.00842881e+00,  1.64816868e+00,  1.39271677e+00,\n",
       "       -4.82323074e+00, -1.43163896e+00, -8.68873835e-01,  2.96400905e+00,\n",
       "       -8.38498783e+00,  1.13679075e+00, -2.76694274e+00, -8.47356856e-01,\n",
       "       -1.29520881e+00, -7.57271528e-01, -1.44508195e+00, -1.95862103e+00,\n",
       "        1.36478882e+01, -6.83783814e-02,  2.98861051e+00,  6.77874994e+00,\n",
       "       -1.44209743e+00,  4.85945940e-01,  4.90947813e-01, -9.49793518e-01,\n",
       "       -3.08351070e-01, -2.42104578e+00, -3.88386965e+00,  4.13553357e-01,\n",
       "       -3.11991990e-01,  3.31496894e-01, -1.78271234e+00,  2.68708444e+00,\n",
       "        3.38924694e+00, -1.07453322e+00,  4.60464668e+00,  2.73648596e+00,\n",
       "       -1.21548247e+00,  1.04993963e+00,  5.53431273e-01,  1.27706182e+00,\n",
       "       -6.29982901e+00,  1.60943365e+00,  1.92335033e+00,  2.30129671e+00,\n",
       "        5.05807686e+00, -1.45295084e+00, -1.40310144e+00,  3.16672611e+00,\n",
       "        7.78714120e-02, -4.65298796e+00,  6.17678285e-01, -8.94923091e-01,\n",
       "        7.21822441e-01, -2.09537601e+00,  3.91176701e+00, -5.20924449e-01,\n",
       "        1.18010139e+00, -1.89140010e+00,  3.42683840e+00, -4.16865885e-01,\n",
       "        2.87270486e-01, -1.19537461e+00,  2.61085302e-01, -1.61160457e+00,\n",
       "        4.54114437e-01,  5.68100750e-01,  4.24272060e-01, -1.74722123e+00,\n",
       "        1.57770336e-01,  5.47249854e-01, -1.61735654e+00, -5.15922964e-01,\n",
       "       -6.17330503e+00,  3.07339096e+00, -2.20980382e+00,  6.58367872e+00,\n",
       "       -5.77075660e-01,  7.02041268e-01, -1.79408026e+00, -1.15416300e+00,\n",
       "        3.93792361e-01,  3.86236858e+00, -8.67751503e+00, -7.73489666e+00,\n",
       "        2.55182296e-01,  2.63545752e+00,  4.75764656e+00, -1.84978580e+00,\n",
       "       -7.81147122e-01,  1.44795775e+00, -9.45440412e-01,  2.32667589e+00,\n",
       "       -3.77631855e+00,  9.24863935e-01,  8.68726969e-01,  8.64214003e-01,\n",
       "        4.39359760e+00,  5.73907606e-02,  8.82733226e-01,  1.27216268e+00,\n",
       "        2.31054589e-01, -3.64874387e+00, -4.35395622e+00,  5.58051944e-01,\n",
       "        9.01268768e+00, -2.64800978e+00, -6.70948565e-01, -4.88998842e+00,\n",
       "        1.57301044e+00, -1.64074039e+00,  1.10779226e+00, -5.65666914e+00,\n",
       "        2.42661524e+00, -2.40560532e+00,  8.21330547e-01,  4.25824070e+00,\n",
       "        1.08947158e-01,  1.75906050e+00, -2.43407202e+00, -1.92546260e+00,\n",
       "        1.98513865e+00,  1.43135285e+00, -2.06201363e+00, -2.68091893e+00,\n",
       "       -5.15804386e+00, -5.68357289e-01,  1.17896207e-01,  1.76266301e+00,\n",
       "       -2.02920294e+00, -8.09635639e-01, -7.93524325e-01,  1.20344925e+01,\n",
       "       -1.65510029e-01, -1.91730201e+00,  7.68638730e-01, -2.53605652e+00,\n",
       "       -4.29259419e-01,  8.30643415e-01, -1.38421714e+00,  1.35334945e+00,\n",
       "        8.42386007e-01, -1.84027660e+00, -8.59076381e-01, -9.23923850e-01,\n",
       "       -1.51335075e-02,  9.20562625e-01,  1.48616838e+00,  1.81744361e+00,\n",
       "       -2.96185672e-01,  1.97506166e+00,  6.31063032e+00, -1.96868801e+00,\n",
       "       -1.14838868e-01,  1.87987232e+00,  8.42111468e-01,  9.11736131e-01,\n",
       "        1.32695186e+00,  2.18755603e+00, -2.01330423e+00,  1.74109697e+00,\n",
       "        2.78216624e+00,  8.56475449e+00,  1.44652224e+01,  6.14478111e-01,\n",
       "        1.25415191e-01, -2.69252634e+00, -5.96837759e+00,  3.23636681e-01,\n",
       "       -2.42742586e+00, -2.02501953e-01, -1.82010472e+00, -9.08871412e-01,\n",
       "       -1.11254616e+01,  1.44540727e+00, -2.09698105e+00, -2.31846762e+00,\n",
       "        2.50024080e-01,  4.72022593e-02,  3.08596802e+00, -7.75624156e-01,\n",
       "       -1.55916393e+00, -1.88882947e-01, -7.57701278e-01, -7.84538865e-01,\n",
       "        6.40918151e-04,  3.08444828e-01, -1.08411050e+00, -2.26615286e+00,\n",
       "       -1.45063341e+00,  5.33611953e-01, -4.41812158e-01, -9.51248550e+00,\n",
       "       -9.75305319e-01, -2.96935499e-01,  3.11014533e+00,  3.10232830e+00,\n",
       "        1.11837399e+00, -3.05369854e+00, -2.17231959e-01,  7.39188731e-01,\n",
       "        3.41967881e-01,  1.38427114e+00, -9.53671455e-01,  1.67576611e+00,\n",
       "        6.07366741e-01,  8.02650392e-01, -7.27992415e-01, -2.46149373e+00,\n",
       "       -7.22841084e-01, -8.96066904e-01,  2.28149915e+00,  1.49996986e+01,\n",
       "       -1.44017243e+00,  1.81486487e+00,  8.89593303e-01, -5.08577442e+00,\n",
       "        9.30229664e-01, -5.71317673e+00,  8.21781218e-01,  8.94372582e-01,\n",
       "        2.80908775e+00,  3.06665373e+00,  1.05773735e+01,  1.73821783e+00,\n",
       "        9.20997739e-01,  2.45633864e+00, -8.48076463e-01,  4.13880646e-01,\n",
       "        3.42252946e+00,  9.13000777e-02, -6.77616787e+00, -3.58141810e-01,\n",
       "       -1.36093497e+00, -1.88806581e+00, -1.51553720e-01,  8.30836833e-01,\n",
       "       -2.58126593e+00, -7.69832850e-01, -2.53276062e+00,  9.68922138e-01,\n",
       "       -8.89636278e-01,  5.76061428e-01,  2.92353034e+00, -4.38642883e+00,\n",
       "        9.19055080e+00,  1.30494189e+00, -2.87818336e+00,  3.08000040e+00,\n",
       "        1.39170992e+00,  3.08141375e+00, -3.55462879e-01, -1.01183498e+00,\n",
       "        8.30021203e-01,  2.03348947e+00, -2.60790348e+00, -1.62007940e+00,\n",
       "       -2.47557664e+00, -3.23212004e+00, -3.54807615e+00,  5.08791566e-01,\n",
       "        2.80247879e+00, -9.03215706e-02,  1.49131393e+00, -6.50690269e+00,\n",
       "       -1.19626379e+00, -1.49845839e+00,  8.79467964e-01, -2.35520244e+00,\n",
       "       -4.31088388e-01,  8.81757021e-01, -4.73818958e-01, -3.12074482e-01,\n",
       "        1.58991599e+00, -1.43130291e+00,  5.25089312e+00, -9.20925713e+00,\n",
       "        1.37350392e+00,  4.49313641e+00,  1.08928907e+00, -1.99299884e+00,\n",
       "       -1.22252960e+01,  7.82933950e+00, -8.30147839e+00, -5.36831260e-01,\n",
       "       -2.21567139e-01,  8.02354622e+00, -7.04843760e+00, -1.27009213e+00,\n",
       "        5.42322922e+00, -2.32207751e+00,  1.84491277e+00, -2.04852200e+00,\n",
       "       -9.72339249e+00,  1.35776401e+00, -1.63230908e+00,  8.38500708e-02,\n",
       "       -2.22220206e+00,  6.74509525e+00, -1.69945812e+00,  2.02583387e-01,\n",
       "        7.89989662e+00,  9.53237891e-01, -1.70869887e+00, -5.56653261e+00,\n",
       "       -1.87023640e+00, -2.93179059e+00, -7.91204572e-02,  1.61066895e+01,\n",
       "        3.23685908e+00, -7.61571169e-01, -1.53184474e+00, -2.18602061e+00,\n",
       "        8.32526147e-01, -3.33600491e-01,  6.32534683e-01,  1.54601860e+01,\n",
       "        5.96148968e+00, -1.18571186e+00, -3.98104548e+00, -1.85396254e-01,\n",
       "       -5.62880874e-01,  1.13817585e+00,  7.02183008e-01,  2.11192465e+00,\n",
       "        4.13337290e-01,  9.04015243e-01,  6.83566451e-01, -1.06393671e+00,\n",
       "       -1.23765039e+00, -1.27455604e+00, -3.99285197e-01,  3.10961580e+00,\n",
       "       -5.91476631e+00,  2.67359197e-01,  2.11868834e+00,  2.42928416e-01,\n",
       "       -1.62928224e-01, -1.71623592e+01,  1.84084225e+00, -1.36137533e+00,\n",
       "        8.57851601e+00, -2.38427758e-01,  8.63651931e-01,  3.89073968e-01,\n",
       "        1.88076198e+00, -1.09708691e+00, -1.47045779e+00,  8.58414471e-01,\n",
       "       -1.09230173e+00,  6.63583219e-01, -2.98756576e+00, -1.99329150e+00,\n",
       "       -1.35522389e+00, -1.98019636e+00, -6.96233213e-01, -7.66400456e-01,\n",
       "        9.12070572e-01,  3.12892175e+00, -5.22769547e+00, -1.42620504e+00,\n",
       "       -2.30103755e+00,  4.08191824e+00, -3.30091691e+00,  1.36457872e+01,\n",
       "       -1.91632164e+00,  8.08129966e-01, -8.14878792e-02,  7.14648306e-01,\n",
       "        2.29367661e+00, -2.87891960e+00,  3.51016670e-01,  1.21286190e+00,\n",
       "        7.22492695e-01,  1.25396562e+00,  2.49234700e+00, -1.39829516e+00,\n",
       "        2.04036862e-01,  5.22332609e-01,  1.27101183e+00, -2.07945752e+00,\n",
       "       -2.94213742e-01, -9.28206503e-01, -1.14667284e+00,  1.12544870e+00,\n",
       "       -1.08497274e+00,  3.92181849e+00, -3.56261921e+00, -4.08683091e-01,\n",
       "       -3.17957401e+00, -3.42118692e+00,  3.01855445e+00,  5.10302126e-01,\n",
       "        1.61191249e+00, -1.17649603e+00,  1.35701275e+00,  1.92876279e+00,\n",
       "       -2.27549243e+00,  1.88682389e+00,  3.61358213e+00,  1.15697403e+01,\n",
       "       -2.22225904e-01, -1.55358124e+00,  1.30943298e+00,  2.53693628e+00,\n",
       "        5.03813773e-02, -1.46257472e+00,  3.25679970e+00,  7.35500395e-01,\n",
       "        1.08570182e+00, -8.25032592e-01,  2.65450668e+00,  3.93471861e+00,\n",
       "       -3.42191994e-01,  2.96994716e-01,  2.30886555e+00, -3.10093117e+00,\n",
       "        1.62972867e+00, -1.31554794e+01,  2.96058607e+00, -1.12986967e-01,\n",
       "       -1.53533626e+00,  1.34396672e+00, -7.27388620e+00,  1.03388417e+00,\n",
       "       -6.50826693e-01, -1.12018538e+00, -1.55081010e+00, -4.02962714e-02,\n",
       "        7.83851445e-01,  1.26692791e+01,  1.31839442e+00,  1.38867807e+01,\n",
       "       -2.26651764e+00, -2.43869472e+00,  1.66996813e+00, -5.62459660e+00,\n",
       "        6.51456118e-02,  8.24550331e-01,  6.77746892e-01,  1.57595050e+00,\n",
       "       -1.46446303e-01, -3.65637040e+00, -2.30885553e+00, -1.07478786e+00,\n",
       "       -8.22218060e-01,  2.14583850e+00,  2.77129865e+00,  1.40597999e+00,\n",
       "        2.70157194e+00,  1.92914224e+00, -1.62461293e+00,  5.65752029e+00,\n",
       "        3.47985089e-01,  2.32817435e+00,  1.88496780e+00,  1.15525827e+01,\n",
       "       -2.35382378e-01, -8.98377150e-02, -1.78638577e+00,  6.72612095e+00,\n",
       "        4.89193559e-01, -1.39563036e+00, -8.57300043e-01,  1.65246201e+00,\n",
       "        7.37751007e+00,  5.48886776e-01,  4.19299185e-01,  1.42369890e+00,\n",
       "       -6.05698109e-01, -1.66957808e+00, -2.98825324e-01,  1.20443192e+01,\n",
       "        1.62613213e+00, -1.25262785e+00, -5.40657938e-01,  6.09058022e-01,\n",
       "        1.18224106e+01,  6.53237700e-01, -6.78617191e+00, -7.25656033e+00,\n",
       "        1.76731098e+00, -1.44645381e+00, -2.42380953e+00, -1.14677763e+00,\n",
       "       -6.35588169e-01, -1.17337692e+00,  6.34919548e+00, -9.75886941e-01,\n",
       "       -8.12237561e-02, -2.12509704e+00, -1.05097961e+00,  1.54281124e-01,\n",
       "       -1.58255911e+00, -3.22371602e+00,  1.05066032e+01,  6.42391980e-01,\n",
       "        2.20723987e+00, -3.55753541e-01, -1.33586019e-01, -9.13654518e+00,\n",
       "       -8.45587730e-01, -1.48367834e+00, -6.02675617e-01, -1.20851135e+01,\n",
       "       -2.22128081e+00, -7.87758350e-01,  1.80517304e+00, -1.12393308e+00,\n",
       "       -6.85730636e-01,  2.29225707e+00, -2.07876444e+00, -2.47926936e-01,\n",
       "       -2.13219023e+00,  8.35012555e-01,  6.74872398e-01, -5.33683002e-01,\n",
       "       -6.51467919e-01,  3.45857358e+00,  1.28107727e+00, -3.87997508e-01,\n",
       "       -1.45276320e+00, -1.81102324e+00, -1.56472006e+01,  5.68066239e-01,\n",
       "        4.66292948e-01, -1.11737657e+00,  1.19082367e+00,  2.14681554e+00,\n",
       "        8.12730694e+00, -2.46088326e-01,  2.62136126e+00,  2.02592826e+00,\n",
       "        9.52842832e-01,  1.09501410e+01,  1.65814269e+00, -1.54915190e+00,\n",
       "       -4.36142415e-01,  3.44157338e+00,  1.82913196e+00,  6.86570072e+00,\n",
       "        1.47723724e+02, -2.73626542e+00,  8.75746822e+00,  4.77366447e+00,\n",
       "        6.36834204e-01, -1.82934177e+00, -9.08712006e+00, -1.70948851e+00,\n",
       "       -1.68720174e+00, -5.99581778e-01, -6.28115311e-02,  4.65575427e-01,\n",
       "       -1.42437530e+00, -1.73493624e+00,  6.13088655e+00, -1.35933888e+00,\n",
       "       -1.39156747e+00,  1.45091712e+00,  1.05548024e+00, -1.72828484e+00,\n",
       "       -2.55481958e-01,  3.22291160e+00,  5.50573587e+00, -4.47257471e+00,\n",
       "        2.51024985e+00, -3.53611857e-01,  2.29557848e+00,  1.70708108e+00,\n",
       "       -9.75264609e-01, -1.49766135e+00, -1.18046832e+00,  4.29635096e+00,\n",
       "       -2.45734596e+00, -1.63768125e+00, -1.31404901e+00,  1.07775078e+01,\n",
       "       -4.92869854e-01, -1.13014567e+00, -1.37144709e+00, -1.04177370e+01,\n",
       "        1.38900268e+00, -5.73305368e+00,  2.59485054e+00, -1.66274261e+00,\n",
       "        1.46769261e+00,  7.89802015e-01, -5.35977840e+00,  2.78887892e+00,\n",
       "       -6.39054894e-01, -6.20821476e-01,  9.01540279e-01,  5.99813271e+00,\n",
       "        9.44960833e-01, -2.57568389e-01,  1.33574116e+00, -1.46749794e+00,\n",
       "       -5.04325962e+00, -1.18676949e+00, -7.36774015e+00, -2.03307509e+00,\n",
       "       -4.49331701e-01,  2.11432552e+00,  2.51790953e+00, -9.90585327e+00,\n",
       "       -1.05456734e+00, -4.30374518e-02, -4.47633803e-01, -3.62604439e-01,\n",
       "       -4.93355654e-02,  8.42336118e-01,  1.45305786e+01,  9.79239273e+00,\n",
       "        3.31013858e-01, -4.09212857e-01, -3.14447045e+00, -2.27645814e-01,\n",
       "        1.21726036e+00, -1.71567988e+00,  2.29889417e+00, -2.38890839e+00,\n",
       "        2.12047026e-01, -2.57594198e-01, -5.84565580e-01, -2.23843575e+00,\n",
       "        3.98960531e-01,  2.58075523e+00,  3.73705482e+00,  1.50951433e+00,\n",
       "        1.08160772e+01, -1.41156577e-02, -3.41973305e-01, -1.37785971e+00,\n",
       "       -8.11174297e+00, -6.24702871e-01, -5.03556609e-01, -1.30344045e+00,\n",
       "       -9.61531830e+00, -2.35140133e+00,  2.01038098e+00,  1.07831144e+00,\n",
       "        1.06233513e+00, -1.17683125e+00,  6.78735971e-01,  2.01203728e+00,\n",
       "       -1.62459517e+00, -4.94735146e+00,  2.56473279e+00, -6.84830666e-01,\n",
       "        2.06800365e+00,  1.80512083e+00, -7.37898290e-01, -1.18678617e+00,\n",
       "       -1.66324723e+00, -1.12719035e+00,  1.37678003e+01, -4.28327084e-01,\n",
       "        3.84424552e-02, -7.40710437e-01,  2.03966069e+00, -3.07526827e-01,\n",
       "        1.10735047e+00,  7.05871487e+00, -1.91164148e+00, -9.98723507e-01,\n",
       "        1.85018122e+00, -8.08255553e-01, -2.00688100e+00,  1.45206511e-01,\n",
       "        8.27261806e-01,  4.22669983e+00, -1.77508783e+00,  8.58287573e-01,\n",
       "        2.79049516e+00,  1.28826284e+01,  6.52409554e-01, -3.31635743e-01,\n",
       "       -6.96167850e+00, -2.09083056e+00,  1.91826320e+00,  3.26785386e-01,\n",
       "       -6.50238097e-01, -1.18929434e+00,  1.47951579e+00,  2.72583634e-01,\n",
       "       -8.88630486e+00,  6.77180946e-01,  5.66121531e+00, -2.76710331e-01,\n",
       "        1.19651318e+00, -3.36685702e-02,  8.46007317e-02,  2.90246201e+00,\n",
       "        4.96572912e-01, -7.83674836e-01, -2.31263012e-01, -1.67857528e+00,\n",
       "        3.62356544e-01,  9.19035339e+00,  4.11747646e+00, -3.64976597e+00,\n",
       "        3.02993774e+00, -7.29753923e+00,  2.18745446e+00, -1.53831458e+00,\n",
       "       -8.95967007e-01,  1.04913175e+00,  3.70324731e+00,  4.37887907e-01,\n",
       "        2.34824586e+00, -2.91517758e+00,  2.74199772e+00, -2.72581995e-01,\n",
       "       -4.07672024e+00,  3.26481080e+00, -2.14753532e+00,  5.38883448e-01,\n",
       "        3.17364001e+00, -1.84366572e+00, -2.44893074e+00,  3.18427372e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1[0]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.29249084e+00,  3.63777781e+00,  4.23399538e-01, -5.11786103e-01,\n",
       "        7.47781098e-02, -1.85845971e+00, -1.18907082e+00,  3.22463453e-01,\n",
       "        1.82019591e-01, -8.84326935e-01,  1.64443004e+00,  4.54211378e+00,\n",
       "       -1.50390983e+00,  9.53911692e-02,  2.49538875e+00,  1.68873161e-01,\n",
       "        7.51633883e-01,  8.81303012e-01,  4.40381795e-01,  8.07001114e-01,\n",
       "       -1.80725384e+00, -3.75910759e-01,  2.27466249e+00,  8.03131580e-01,\n",
       "        4.10848904e+00, -2.06890091e-01,  2.81727195e+00,  2.45356965e+00,\n",
       "        2.50195801e-01,  4.23120975e+00, -4.32547152e-01, -1.03654042e-01,\n",
       "        1.33408270e+01, -1.26888728e+00,  1.80050611e+00, -6.77784383e-01,\n",
       "       -1.90651193e-01,  2.86780930e+00, -1.35983837e+00,  1.97166115e-01,\n",
       "       -3.90152240e+00, -8.99383277e-02, -9.23913288e+00,  1.73467016e+00,\n",
       "        3.70687723e+00, -1.63211018e-01,  2.73611218e-01,  2.59661579e+00,\n",
       "       -9.53045428e-01,  1.00355470e+00,  1.64675689e+00,  1.38660443e+00,\n",
       "       -4.82615662e+00, -1.43167019e+00, -8.69223356e-01,  2.96613646e+00,\n",
       "       -8.38259315e+00,  1.14338493e+00, -2.76951194e+00, -8.47635806e-01,\n",
       "       -1.29359615e+00, -7.56328583e-01, -1.43669617e+00, -1.95359850e+00,\n",
       "        1.36355104e+01, -7.00581148e-02,  2.98630261e+00,  6.78275585e+00,\n",
       "       -1.44992065e+00,  4.87179577e-01,  4.89973158e-01, -9.45884585e-01,\n",
       "       -3.14815760e-01, -2.41238809e+00, -3.87599206e+00,  4.19670761e-01,\n",
       "       -3.17479014e-01,  3.33687514e-01, -1.78469551e+00,  2.68756127e+00,\n",
       "        3.38779783e+00, -1.08162916e+00,  4.61412382e+00,  2.73180461e+00,\n",
       "       -1.22530377e+00,  1.06062090e+00,  5.58418989e-01,  1.28001928e+00,\n",
       "       -6.29152870e+00,  1.60780537e+00,  1.92454839e+00,  2.30224514e+00,\n",
       "        5.05159378e+00, -1.44486082e+00, -1.40570092e+00,  3.16323972e+00,\n",
       "        7.75637105e-02, -4.64709425e+00,  6.18516028e-01, -8.91364515e-01,\n",
       "        7.17546642e-01, -2.10136151e+00,  3.89781237e+00, -5.20451963e-01,\n",
       "        1.18319678e+00, -1.88145351e+00,  3.41796350e+00, -4.08133447e-01,\n",
       "        2.82953143e-01, -1.19136620e+00,  2.49248177e-01, -1.60090137e+00,\n",
       "        4.62502122e-01,  5.74244022e-01,  4.29614782e-01, -1.75559425e+00,\n",
       "        1.54247269e-01,  5.53448558e-01, -1.62205708e+00, -5.30501664e-01,\n",
       "       -6.16883659e+00,  3.06492901e+00, -2.21147633e+00,  6.58820438e+00,\n",
       "       -5.68710864e-01,  7.07012415e-01, -1.79283834e+00, -1.13992310e+00,\n",
       "        3.94605458e-01,  3.86282921e+00, -8.67736053e+00, -7.72870016e+00,\n",
       "        2.47088894e-01,  2.63253808e+00,  4.75242186e+00, -1.84506941e+00,\n",
       "       -7.80863643e-01,  1.44538236e+00, -9.38069761e-01,  2.32477713e+00,\n",
       "       -3.78268671e+00,  9.15230215e-01,  8.62202168e-01,  8.66457820e-01,\n",
       "        4.39343071e+00,  6.20187223e-02,  8.82035136e-01,  1.27151155e+00,\n",
       "        2.32292041e-01, -3.63640189e+00, -4.34891033e+00,  5.61631799e-01,\n",
       "        9.01976967e+00, -2.63873339e+00, -6.74064219e-01, -4.89361238e+00,\n",
       "        1.56787026e+00, -1.63612473e+00,  1.10482919e+00, -5.64229059e+00,\n",
       "        2.42255020e+00, -2.39591026e+00,  8.14061761e-01,  4.25878334e+00,\n",
       "        1.08350426e-01,  1.75940585e+00, -2.41937971e+00, -1.92629385e+00,\n",
       "        1.99181390e+00,  1.43102980e+00, -2.06427908e+00, -2.67666793e+00,\n",
       "       -5.15749454e+00, -5.65567970e-01,  1.15504995e-01,  1.76799369e+00,\n",
       "       -2.02417588e+00, -8.13028574e-01, -7.91893125e-01,  1.20323992e+01,\n",
       "       -1.62179708e-01, -1.91246605e+00,  7.61979878e-01, -2.53351593e+00,\n",
       "       -4.26912427e-01,  8.34839702e-01, -1.38822603e+00,  1.35209155e+00,\n",
       "        8.37284327e-01, -1.83049214e+00, -8.65882516e-01, -9.24964488e-01,\n",
       "       -1.78859923e-02,  9.20034945e-01,  1.47966528e+00,  1.81812215e+00,\n",
       "       -2.88776129e-01,  1.97565079e+00,  6.30872059e+00, -1.95881534e+00,\n",
       "       -1.09741867e-01,  1.88032734e+00,  8.48507345e-01,  9.12552834e-01,\n",
       "        1.33585703e+00,  2.17851710e+00, -2.00815248e+00,  1.74527216e+00,\n",
       "        2.78255463e+00,  8.56814671e+00,  1.44654856e+01,  6.12647593e-01,\n",
       "        1.30000144e-01, -2.68849635e+00, -5.96737289e+00,  3.24776351e-01,\n",
       "       -2.41766548e+00, -1.94478273e-01, -1.82477021e+00, -9.03210878e-01,\n",
       "       -1.11230164e+01,  1.44908857e+00, -2.10117960e+00, -2.32028222e+00,\n",
       "        2.41371915e-01,  4.81351130e-02,  3.09014559e+00, -7.77780712e-01,\n",
       "       -1.56028199e+00, -1.96218312e-01, -7.51035213e-01, -7.82516301e-01,\n",
       "        5.74260391e-03,  3.10911983e-01, -1.08357680e+00, -2.27174354e+00,\n",
       "       -1.43594384e+00,  5.30573905e-01, -4.41597670e-01, -9.50484562e+00,\n",
       "       -9.73302603e-01, -2.92088062e-01,  3.11365151e+00,  3.10056305e+00,\n",
       "        1.11910689e+00, -3.05185032e+00, -2.18865335e-01,  7.49101400e-01,\n",
       "        3.35952401e-01,  1.38440382e+00, -9.44483817e-01,  1.66581094e+00,\n",
       "        5.99146366e-01,  7.96221733e-01, -7.28419721e-01, -2.45713782e+00,\n",
       "       -7.27940321e-01, -8.97914827e-01,  2.28464890e+00,  1.49951944e+01,\n",
       "       -1.43791366e+00,  1.80981255e+00,  8.92610192e-01, -5.09206676e+00,\n",
       "        9.28931534e-01, -5.71556473e+00,  8.21375608e-01,  8.91749322e-01,\n",
       "        2.80249310e+00,  3.06505871e+00,  1.05749664e+01,  1.73906994e+00,\n",
       "        9.23016906e-01,  2.45579815e+00, -8.44559550e-01,  4.11587596e-01,\n",
       "        3.41227245e+00,  9.63110775e-02, -6.76248074e+00, -3.60744536e-01,\n",
       "       -1.36268318e+00, -1.88322377e+00, -1.56978801e-01,  8.16153526e-01,\n",
       "       -2.58201504e+00, -7.72833824e-01, -2.52139354e+00,  9.69562173e-01,\n",
       "       -8.77897143e-01,  5.71201563e-01,  2.92395115e+00, -4.38025379e+00,\n",
       "        9.18095970e+00,  1.31154644e+00, -2.88319373e+00,  3.06733894e+00,\n",
       "        1.38617015e+00,  3.08314896e+00, -3.54246855e-01, -1.01044691e+00,\n",
       "        8.37178767e-01,  2.02917337e+00, -2.61043596e+00, -1.61223125e+00,\n",
       "       -2.48548174e+00, -3.23392606e+00, -3.54095316e+00,  5.04271924e-01,\n",
       "        2.79863501e+00, -8.35160911e-02,  1.49429667e+00, -6.50623369e+00,\n",
       "       -1.19817114e+00, -1.49020076e+00,  8.83368909e-01, -2.35797143e+00,\n",
       "       -4.35938507e-01,  8.83465528e-01, -4.66216505e-01, -3.10465455e-01,\n",
       "        1.59335029e+00, -1.43246436e+00,  5.25157261e+00, -9.20902824e+00,\n",
       "        1.36913443e+00,  4.49199247e+00,  1.09325993e+00, -1.99234986e+00,\n",
       "       -1.22238064e+01,  7.83264828e+00, -8.30381107e+00, -5.30655861e-01,\n",
       "       -2.20875815e-01,  8.01958847e+00, -7.04758549e+00, -1.26736283e+00,\n",
       "        5.41723156e+00, -2.32081509e+00,  1.84283793e+00, -2.04721212e+00,\n",
       "       -9.71737003e+00,  1.35729539e+00, -1.62590909e+00,  8.17267969e-02,\n",
       "       -2.22015071e+00,  6.73833656e+00, -1.68776870e+00,  2.03662500e-01,\n",
       "        7.90067959e+00,  9.41591144e-01, -1.71253324e+00, -5.55883455e+00,\n",
       "       -1.87260389e+00, -2.94067764e+00, -7.76735842e-02,  1.60998631e+01,\n",
       "        3.23920274e+00, -7.64599800e-01, -1.53861272e+00, -2.16487622e+00,\n",
       "        8.22534084e-01, -3.30666572e-01,  6.34483099e-01,  1.54502192e+01,\n",
       "        5.95888233e+00, -1.18663716e+00, -3.97629118e+00, -1.85389638e-01,\n",
       "       -5.58864951e-01,  1.13385618e+00,  7.02848673e-01,  2.11167479e+00,\n",
       "        4.16154861e-01,  9.02062774e-01,  6.85566187e-01, -1.06913912e+00,\n",
       "       -1.23499954e+00, -1.27671289e+00, -3.93297195e-01,  3.10177469e+00,\n",
       "       -5.91003799e+00,  2.76964426e-01,  2.11382031e+00,  2.45611548e-01,\n",
       "       -1.61568552e-01, -1.71549397e+01,  1.83933568e+00, -1.36302853e+00,\n",
       "        8.57702351e+00, -2.45960295e-01,  8.61744165e-01,  3.97177875e-01,\n",
       "        1.86777174e+00, -1.08863664e+00, -1.47006440e+00,  8.63500297e-01,\n",
       "       -1.09547794e+00,  6.74781740e-01, -2.98752332e+00, -1.99638259e+00,\n",
       "       -1.35819852e+00, -1.98333859e+00, -6.97337389e-01, -7.64408231e-01,\n",
       "        9.01675224e-01,  3.11515093e+00, -5.21748304e+00, -1.42406344e+00,\n",
       "       -2.30045366e+00,  4.07286072e+00, -3.29658246e+00,  1.36384096e+01,\n",
       "       -1.91477644e+00,  8.17728162e-01, -8.52617994e-02,  7.18222857e-01,\n",
       "        2.29719114e+00, -2.88193893e+00,  3.53102565e-01,  1.20948291e+00,\n",
       "        7.25789368e-01,  1.25476897e+00,  2.48852324e+00, -1.40698481e+00,\n",
       "        2.06677094e-01,  5.18400311e-01,  1.26685262e+00, -2.08079076e+00,\n",
       "       -2.93193787e-01, -9.27047491e-01, -1.14209402e+00,  1.11501384e+00,\n",
       "       -1.07895851e+00,  3.91318321e+00, -3.55668783e+00, -4.17181671e-01,\n",
       "       -3.17490458e+00, -3.41892719e+00,  3.02425027e+00,  5.02898097e-01,\n",
       "        1.61158860e+00, -1.17822194e+00,  1.35585129e+00,  1.91656303e+00,\n",
       "       -2.27576518e+00,  1.89012814e+00,  3.61738420e+00,  1.15580139e+01,\n",
       "       -2.21517622e-01, -1.55315816e+00,  1.30891442e+00,  2.53475332e+00,\n",
       "        4.95266505e-02, -1.42989039e+00,  3.25758505e+00,  7.24735141e-01,\n",
       "        1.08207393e+00, -8.19731414e-01,  2.65098524e+00,  3.93221354e+00,\n",
       "       -3.39919180e-01,  2.91315079e-01,  2.30983591e+00, -3.09067941e+00,\n",
       "        1.63259804e+00, -1.31447687e+01,  2.95943213e+00, -1.22113369e-01,\n",
       "       -1.53254044e+00,  1.35385132e+00, -7.26142836e+00,  1.04148769e+00,\n",
       "       -6.55138969e-01, -1.11939764e+00, -1.55098557e+00, -4.55828197e-02,\n",
       "        7.78595328e-01,  1.26669941e+01,  1.31757474e+00,  1.38870411e+01,\n",
       "       -2.26015449e+00, -2.43374801e+00,  1.66421640e+00, -5.61966038e+00,\n",
       "        6.95943609e-02,  8.24765682e-01,  6.77317441e-01,  1.56871808e+00,\n",
       "       -1.47163540e-01, -3.64585423e+00, -2.30691385e+00, -1.07355213e+00,\n",
       "       -8.22566211e-01,  2.15211606e+00,  2.77472520e+00,  1.40510941e+00,\n",
       "        2.69416785e+00,  1.93380022e+00, -1.62418652e+00,  5.65607357e+00,\n",
       "        3.42772007e-01,  2.32573605e+00,  1.88767457e+00,  1.15576744e+01,\n",
       "       -2.33912393e-01, -8.63194540e-02, -1.78359389e+00,  6.72109795e+00,\n",
       "        4.94854331e-01, -1.39151943e+00, -8.60140383e-01,  1.63937795e+00,\n",
       "        7.37541437e+00,  5.48730373e-01,  4.20088500e-01,  1.42026591e+00,\n",
       "       -6.06840968e-01, -1.66713643e+00, -2.99570680e-01,  1.20284948e+01,\n",
       "        1.62953436e+00, -1.25314415e+00, -5.43881118e-01,  6.09262347e-01,\n",
       "        1.18214989e+01,  6.46618843e-01, -6.78963757e+00, -7.26013756e+00,\n",
       "        1.76684237e+00, -1.44532108e+00, -2.42980623e+00, -1.13828993e+00,\n",
       "       -6.32345021e-01, -1.17429543e+00,  6.34701920e+00, -9.74364400e-01,\n",
       "       -8.52105319e-02, -2.12196636e+00, -1.04872954e+00,  1.50164247e-01,\n",
       "       -1.57467747e+00, -3.21874571e+00,  1.05030909e+01,  6.44389510e-01,\n",
       "        2.21055222e+00, -3.50840956e-01, -1.39349550e-01, -9.12534809e+00,\n",
       "       -8.44634891e-01, -1.47564888e+00, -6.00048423e-01, -1.20881157e+01,\n",
       "       -2.21832657e+00, -7.80239940e-01,  1.81012058e+00, -1.11825931e+00,\n",
       "       -6.82842016e-01,  2.29595017e+00, -2.07868290e+00, -2.53657281e-01,\n",
       "       -2.14315844e+00,  8.48774195e-01,  6.74226880e-01, -5.35693407e-01,\n",
       "       -6.49783492e-01,  3.45393658e+00,  1.27091503e+00, -3.97617519e-01,\n",
       "       -1.44719493e+00, -1.80366158e+00, -1.56339684e+01,  5.67853689e-01,\n",
       "        4.74758327e-01, -1.11051583e+00,  1.19029331e+00,  2.13401222e+00,\n",
       "        8.12452698e+00, -2.46504188e-01,  2.62244749e+00,  2.02314472e+00,\n",
       "        9.55511391e-01,  1.09450550e+01,  1.66165853e+00, -1.55023468e+00,\n",
       "       -4.45074439e-01,  3.44394970e+00,  1.82713866e+00,  6.85239697e+00,\n",
       "        1.47652573e+02, -2.72750974e+00,  8.75847626e+00,  4.76604366e+00,\n",
       "        6.34408295e-01, -1.83715212e+00, -9.08272266e+00, -1.70997190e+00,\n",
       "       -1.69571614e+00, -6.01003408e-01, -5.54608144e-02,  4.63821471e-01,\n",
       "       -1.41610289e+00, -1.73690009e+00,  6.12377453e+00, -1.36146259e+00,\n",
       "       -1.39794326e+00,  1.44259214e+00,  1.05709779e+00, -1.73217106e+00,\n",
       "       -2.61672258e-01,  3.21548700e+00,  5.49714613e+00, -4.46487951e+00,\n",
       "        2.50965738e+00, -3.57435971e-01,  2.30831814e+00,  1.70597124e+00,\n",
       "       -9.72444654e-01, -1.50321150e+00, -1.17352617e+00,  4.28024340e+00,\n",
       "       -2.44589496e+00, -1.63192391e+00, -1.31664038e+00,  1.07817221e+01,\n",
       "       -5.01441896e-01, -1.13273156e+00, -1.36976969e+00, -1.04129744e+01,\n",
       "        1.38899851e+00, -5.72710609e+00,  2.58999634e+00, -1.65516007e+00,\n",
       "        1.46548223e+00,  7.89666116e-01, -5.35333109e+00,  2.77829051e+00,\n",
       "       -6.34007335e-01, -6.19865417e-01,  8.96326363e-01,  5.98994350e+00,\n",
       "        9.35417354e-01, -2.56942272e-01,  1.33710384e+00, -1.46209669e+00,\n",
       "       -5.03545189e+00, -1.18446743e+00, -7.36176491e+00, -2.02770686e+00,\n",
       "       -4.51534927e-01,  2.10863781e+00,  2.51491404e+00, -9.90315056e+00,\n",
       "       -1.05327773e+00, -4.55356948e-02, -4.45765078e-01, -3.62034291e-01,\n",
       "       -4.25994992e-02,  8.43335330e-01,  1.45319738e+01,  9.78838825e+00,\n",
       "        3.27510595e-01, -4.16876018e-01, -3.14485025e+00, -2.29723915e-01,\n",
       "        1.21840346e+00, -1.71072721e+00,  2.29435182e+00, -2.38933587e+00,\n",
       "        2.09602803e-01, -2.55812764e-01, -5.94018757e-01, -2.24152708e+00,\n",
       "        3.93193901e-01,  2.57738447e+00,  3.73092127e+00,  1.51402330e+00,\n",
       "        1.08118238e+01, -1.45643111e-02, -3.33328009e-01, -1.38619637e+00,\n",
       "       -8.11140442e+00, -6.13660634e-01, -4.96665418e-01, -1.30527091e+00,\n",
       "       -9.61404037e+00, -2.35589600e+00,  2.01437759e+00,  1.07694173e+00,\n",
       "        1.05265641e+00, -1.16996598e+00,  6.84958041e-01,  2.01407576e+00,\n",
       "       -1.62678266e+00, -4.94920683e+00,  2.56728196e+00, -6.81907773e-01,\n",
       "        2.07596827e+00,  1.80110395e+00, -7.32229352e-01, -1.18536341e+00,\n",
       "       -1.65406680e+00, -1.13306832e+00,  1.37615480e+01, -4.29045707e-01,\n",
       "        3.99358273e-02, -7.39547610e-01,  2.03579092e+00, -3.17550927e-01,\n",
       "        1.09723127e+00,  7.05688047e+00, -1.90200949e+00, -1.00865948e+00,\n",
       "        1.84586430e+00, -8.06500793e-01, -2.00519300e+00,  1.44567758e-01,\n",
       "        8.26437712e-01,  4.22201777e+00, -1.77308607e+00,  8.68741989e-01,\n",
       "        2.78505707e+00,  1.28753147e+01,  6.53175771e-01, -3.27758312e-01,\n",
       "       -6.94726086e+00, -2.09905005e+00,  1.90801001e+00,  3.28172475e-01,\n",
       "       -6.47684813e-01, -1.19002473e+00,  1.47679150e+00,  2.68728614e-01,\n",
       "       -8.87590981e+00,  6.72850609e-01,  5.65484905e+00, -2.71188587e-01,\n",
       "        1.19993079e+00, -3.87618877e-02,  7.88224116e-02,  2.90143871e+00,\n",
       "        4.96280909e-01, -7.83413708e-01, -2.26403147e-01, -1.68704271e+00,\n",
       "        3.61826599e-01,  9.18141937e+00,  4.11675453e+00, -3.64495730e+00,\n",
       "        3.02389479e+00, -7.29061413e+00,  2.18897939e+00, -1.54051673e+00,\n",
       "       -8.93945217e-01,  1.04427886e+00,  3.69398499e+00,  4.30648685e-01,\n",
       "        2.35010767e+00, -2.90935254e+00,  2.73551369e+00, -2.75875956e-01,\n",
       "       -4.07483959e+00,  3.25870323e+00, -2.14545155e+00,  5.44725597e-01,\n",
       "        3.17105055e+00, -1.84087861e+00, -2.45136285e+00,  3.18487144e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec3[0]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.29180300e+00,  3.63768816e+00,  4.24564213e-01, -5.12851536e-01,\n",
       "        7.61273354e-02, -1.85731590e+00, -1.18962169e+00,  3.23152274e-01,\n",
       "        1.82970196e-01, -8.83300960e-01,  1.64352393e+00,  4.54157066e+00,\n",
       "       -1.50436306e+00,  9.68452170e-02,  2.49508214e+00,  1.68422624e-01,\n",
       "        7.51626492e-01,  8.82704973e-01,  4.39172119e-01,  8.06280017e-01,\n",
       "       -1.80711174e+00, -3.76266241e-01,  2.27340317e+00,  8.02632034e-01,\n",
       "        4.10874748e+00, -2.07517132e-01,  2.81509137e+00,  2.45311642e+00,\n",
       "        2.49621704e-01,  4.22967863e+00, -4.32460189e-01, -1.03013247e-01,\n",
       "        1.33380985e+01, -1.26897931e+00,  1.80030608e+00, -6.76399112e-01,\n",
       "       -1.92339212e-01,  2.86650300e+00, -1.36011958e+00,  1.97826013e-01,\n",
       "       -3.90287113e+00, -9.04887915e-02, -9.23724270e+00,  1.73574376e+00,\n",
       "        3.70623732e+00, -1.61388204e-01,  2.73872793e-01,  2.59531355e+00,\n",
       "       -9.53783333e-01,  1.00329244e+00,  1.64722383e+00,  1.38788962e+00,\n",
       "       -4.82564068e+00, -1.43057287e+00, -8.68680954e-01,  2.96459317e+00,\n",
       "       -8.38236046e+00,  1.14469635e+00, -2.76945925e+00, -8.47290277e-01,\n",
       "       -1.29401112e+00, -7.56202996e-01, -1.43544650e+00, -1.95251107e+00,\n",
       "        1.36332150e+01, -6.86939061e-02,  2.98435473e+00,  6.77951574e+00,\n",
       "       -1.45045042e+00,  4.87246931e-01,  4.88374561e-01, -9.45953131e-01,\n",
       "       -3.15595001e-01, -2.41051102e+00, -3.87473249e+00,  4.20787781e-01,\n",
       "       -3.16510171e-01,  3.34608436e-01, -1.78400624e+00,  2.68709755e+00,\n",
       "        3.38858485e+00, -1.08266115e+00,  4.61524439e+00,  2.73195362e+00,\n",
       "       -1.22517216e+00,  1.06151628e+00,  5.59277713e-01,  1.27972102e+00,\n",
       "       -6.29109287e+00,  1.60637951e+00,  1.92350435e+00,  2.30335140e+00,\n",
       "        5.04937553e+00, -1.44484901e+00, -1.40519381e+00,  3.16214895e+00,\n",
       "        7.72832036e-02, -4.64403820e+00,  6.18769288e-01, -8.91636550e-01,\n",
       "        7.16006875e-01, -2.10019088e+00,  3.89593697e+00, -5.18335581e-01,\n",
       "        1.18303728e+00, -1.88001573e+00,  3.41861749e+00, -4.06892300e-01,\n",
       "        2.84568012e-01, -1.19260383e+00,  2.47695073e-01, -1.60076606e+00,\n",
       "        4.63866144e-01,  5.74991286e-01,  4.30613697e-01, -1.75651324e+00,\n",
       "        1.54309660e-01,  5.54913521e-01, -1.62256694e+00, -5.33323050e-01,\n",
       "       -6.16674519e+00,  3.06350040e+00, -2.21080136e+00,  6.58614397e+00,\n",
       "       -5.66295385e-01,  7.07090437e-01, -1.79262924e+00, -1.13842309e+00,\n",
       "        3.94373387e-01,  3.86159396e+00, -8.67507172e+00, -7.72847414e+00,\n",
       "        2.46921360e-01,  2.63473773e+00,  4.75219250e+00, -1.84470034e+00,\n",
       "       -7.79365361e-01,  1.44639957e+00, -9.38280761e-01,  2.32399893e+00,\n",
       "       -3.78197217e+00,  9.15008068e-01,  8.60492885e-01,  8.66067648e-01,\n",
       "        4.39370823e+00,  6.28701076e-02,  8.82427752e-01,  1.27205026e+00,\n",
       "        2.33377904e-01, -3.63473415e+00, -4.34656572e+00,  5.61500967e-01,\n",
       "        9.01861000e+00, -2.63740635e+00, -6.73466325e-01, -4.89317036e+00,\n",
       "        1.56876349e+00, -1.63420856e+00,  1.10482371e+00, -5.63960934e+00,\n",
       "        2.42242908e+00, -2.39504862e+00,  8.12912643e-01,  4.25705385e+00,\n",
       "        1.06897049e-01,  1.75813091e+00, -2.41926384e+00, -1.92483521e+00,\n",
       "        1.99163032e+00,  1.43077505e+00, -2.06453061e+00, -2.67519951e+00,\n",
       "       -5.15637970e+00, -5.65660834e-01,  1.16002567e-01,  1.76703715e+00,\n",
       "       -2.02277231e+00, -8.13255548e-01, -7.91669428e-01,  1.20291891e+01,\n",
       "       -1.61084801e-01, -1.91189575e+00,  7.62773097e-01, -2.53399253e+00,\n",
       "       -4.26734209e-01,  8.35690737e-01, -1.38785958e+00,  1.35171175e+00,\n",
       "        8.37466180e-01, -1.82790303e+00, -8.66552889e-01, -9.25329089e-01,\n",
       "       -1.71941519e-02,  9.20757592e-01,  1.47961390e+00,  1.81739330e+00,\n",
       "       -2.88519323e-01,  1.97550702e+00,  6.30748796e+00, -1.95729446e+00,\n",
       "       -1.09571546e-01,  1.88154769e+00,  8.48175406e-01,  9.12202299e-01,\n",
       "        1.33744740e+00,  2.17798114e+00, -2.00691056e+00,  1.74453044e+00,\n",
       "        2.78352356e+00,  8.56619835e+00,  1.44644537e+01,  6.11533284e-01,\n",
       "        1.29866168e-01, -2.68842554e+00, -5.96670437e+00,  3.24562848e-01,\n",
       "       -2.41654587e+00, -1.93646118e-01, -1.82519102e+00, -9.02505159e-01,\n",
       "       -1.11211109e+01,  1.44798863e+00, -2.10172486e+00, -2.31965733e+00,\n",
       "        2.40336359e-01,  4.81662154e-02,  3.09009218e+00, -7.78353155e-01,\n",
       "       -1.56097579e+00, -1.98228806e-01, -7.49803066e-01, -7.82288969e-01,\n",
       "        6.37583248e-03,  3.10306519e-01, -1.08091843e+00, -2.27279520e+00,\n",
       "       -1.43393779e+00,  5.29911876e-01, -4.40781057e-01, -9.50230980e+00,\n",
       "       -9.73575056e-01, -2.90752023e-01,  3.11422324e+00,  3.09952688e+00,\n",
       "        1.11776233e+00, -3.05268955e+00, -2.16897592e-01,  7.48567700e-01,\n",
       "        3.36197197e-01,  1.38386202e+00, -9.43480790e-01,  1.66531849e+00,\n",
       "        5.98918319e-01,  7.94940233e-01, -7.28607655e-01, -2.45643878e+00,\n",
       "       -7.28131294e-01, -8.97885025e-01,  2.28529787e+00,  1.49933319e+01,\n",
       "       -1.43761778e+00,  1.80738044e+00,  8.92952919e-01, -5.09192228e+00,\n",
       "        9.27399695e-01, -5.71417141e+00,  8.22186470e-01,  8.90842140e-01,\n",
       "        2.80114698e+00,  3.06272483e+00,  1.05730457e+01,  1.73742270e+00,\n",
       "        9.22820866e-01,  2.45481920e+00, -8.43067408e-01,  4.11358953e-01,\n",
       "        3.40945482e+00,  9.74196494e-02, -6.76079178e+00, -3.60432625e-01,\n",
       "       -1.36427534e+00, -1.88435781e+00, -1.57506227e-01,  8.16009879e-01,\n",
       "       -2.58218908e+00, -7.73727536e-01, -2.52067780e+00,  9.69821692e-01,\n",
       "       -8.77199054e-01,  5.68271160e-01,  2.92254806e+00, -4.37990427e+00,\n",
       "        9.17873192e+00,  1.31132936e+00, -2.88257933e+00,  3.06665421e+00,\n",
       "        1.38643801e+00,  3.08225584e+00, -3.54641706e-01, -1.01001287e+00,\n",
       "        8.38398635e-01,  2.02814102e+00, -2.61088586e+00, -1.60995293e+00,\n",
       "       -2.48565817e+00, -3.23396206e+00, -3.53890133e+00,  5.03190637e-01,\n",
       "        2.79944444e+00, -8.29508007e-02,  1.49428988e+00, -6.50535965e+00,\n",
       "       -1.19779193e+00, -1.48747468e+00,  8.83631706e-01, -2.35788608e+00,\n",
       "       -4.36469495e-01,  8.82438302e-01, -4.65677500e-01, -3.10152918e-01,\n",
       "        1.59264147e+00, -1.43324423e+00,  5.24956322e+00, -9.20661545e+00,\n",
       "        1.36785245e+00,  4.49075365e+00,  1.09259641e+00, -1.99127197e+00,\n",
       "       -1.22212029e+01,  7.83180332e+00, -8.30414581e+00, -5.28595686e-01,\n",
       "       -2.20461398e-01,  8.01863289e+00, -7.04740095e+00, -1.26740158e+00,\n",
       "        5.41567850e+00, -2.31972075e+00,  1.84294116e+00, -2.04696989e+00,\n",
       "       -9.71643639e+00,  1.35670900e+00, -1.62563920e+00,  8.21418911e-02,\n",
       "       -2.21861744e+00,  6.73584080e+00, -1.68683434e+00,  2.03800112e-01,\n",
       "        7.89916754e+00,  9.42055225e-01, -1.71319497e+00, -5.55656481e+00,\n",
       "       -1.87161350e+00, -2.93931460e+00, -7.64996633e-02,  1.60961609e+01,\n",
       "        3.23936439e+00, -7.65318513e-01, -1.53818846e+00, -2.16217494e+00,\n",
       "        8.21568131e-01, -3.31745774e-01,  6.36409581e-01,  1.54473286e+01,\n",
       "        5.95852137e+00, -1.18643880e+00, -3.97563839e+00, -1.84832975e-01,\n",
       "       -5.58526456e-01,  1.13443899e+00,  7.03264117e-01,  2.11228848e+00,\n",
       "        4.16139781e-01,  9.00965393e-01,  6.84278667e-01, -1.06961441e+00,\n",
       "       -1.23343611e+00, -1.27636182e+00, -3.94103765e-01,  3.10100985e+00,\n",
       "       -5.90909290e+00,  2.76922554e-01,  2.11476111e+00,  2.44986281e-01,\n",
       "       -1.61206648e-01, -1.71535416e+01,  1.83936477e+00, -1.36152673e+00,\n",
       "        8.57489109e+00, -2.47554272e-01,  8.61631513e-01,  3.98033619e-01,\n",
       "        1.86573160e+00, -1.08860910e+00, -1.47021222e+00,  8.62945080e-01,\n",
       "       -1.09507179e+00,  6.74125314e-01, -2.98593163e+00, -1.99630201e+00,\n",
       "       -1.35728407e+00, -1.98200953e+00, -6.97797894e-01, -7.66380072e-01,\n",
       "        8.99750233e-01,  3.11456895e+00, -5.21684265e+00, -1.42484808e+00,\n",
       "       -2.29965091e+00,  4.07228470e+00, -3.29696059e+00,  1.36355677e+01,\n",
       "       -1.91456604e+00,  8.17782521e-01, -8.63809958e-02,  7.18021631e-01,\n",
       "        2.29826832e+00, -2.88337040e+00,  3.53515893e-01,  1.20827579e+00,\n",
       "        7.26107359e-01,  1.25499785e+00,  2.48760962e+00, -1.40735376e+00,\n",
       "        2.08620548e-01,  5.18456042e-01,  1.26709890e+00, -2.08026743e+00,\n",
       "       -2.90069997e-01, -9.27069664e-01, -1.14196634e+00,  1.11322427e+00,\n",
       "       -1.07928109e+00,  3.91272593e+00, -3.55668759e+00, -4.17990714e-01,\n",
       "       -3.17402124e+00, -3.41798115e+00,  3.02357388e+00,  5.02294779e-01,\n",
       "        1.61139798e+00, -1.17767680e+00,  1.35720348e+00,  1.91433859e+00,\n",
       "       -2.27372861e+00,  1.89032674e+00,  3.61526108e+00,  1.15560446e+01,\n",
       "       -2.21045598e-01, -1.55232167e+00,  1.30924296e+00,  2.53361034e+00,\n",
       "        5.01225963e-02, -1.42807972e+00,  3.25709677e+00,  7.23139644e-01,\n",
       "        1.08294594e+00, -8.18524361e-01,  2.65055418e+00,  3.93281460e+00,\n",
       "       -3.40209007e-01,  2.91171342e-01,  2.30944061e+00, -3.09049416e+00,\n",
       "        1.63293409e+00, -1.31436148e+01,  2.95963907e+00, -1.20680079e-01,\n",
       "       -1.53029966e+00,  1.35410929e+00, -7.25910282e+00,  1.04218149e+00,\n",
       "       -6.55182302e-01, -1.12035024e+00, -1.55148566e+00, -4.65811267e-02,\n",
       "        7.76684046e-01,  1.26643133e+01,  1.31678867e+00,  1.38843355e+01,\n",
       "       -2.26066613e+00, -2.43546104e+00,  1.66397345e+00, -5.61658096e+00,\n",
       "        6.81276321e-02,  8.24196577e-01,  6.75637066e-01,  1.56902099e+00,\n",
       "       -1.46013618e-01, -3.64512444e+00, -2.30662060e+00, -1.07598186e+00,\n",
       "       -8.21524262e-01,  2.15317225e+00,  2.77568865e+00,  1.40470982e+00,\n",
       "        2.69381714e+00,  1.93348813e+00, -1.62462568e+00,  5.65453148e+00,\n",
       "        3.43019068e-01,  2.32642555e+00,  1.88738596e+00,  1.15558004e+01,\n",
       "       -2.34767422e-01, -8.55594203e-02, -1.78359079e+00,  6.71910715e+00,\n",
       "        4.95143533e-01, -1.39067054e+00, -8.61257374e-01,  1.63981271e+00,\n",
       "        7.37406921e+00,  5.49068749e-01,  4.20005262e-01,  1.41989172e+00,\n",
       "       -6.06472075e-01, -1.66719902e+00, -3.00155163e-01,  1.20245752e+01,\n",
       "        1.62824059e+00, -1.25260687e+00, -5.44016421e-01,  6.07332051e-01,\n",
       "        1.18191824e+01,  6.46373510e-01, -6.78818989e+00, -7.25934553e+00,\n",
       "        1.76617157e+00, -1.44676280e+00, -2.42864084e+00, -1.13692391e+00,\n",
       "       -6.30448401e-01, -1.17349029e+00,  6.34312105e+00, -9.73915994e-01,\n",
       "       -8.60047638e-02, -2.12075377e+00, -1.04958427e+00,  1.49279952e-01,\n",
       "       -1.57456851e+00, -3.21874332e+00,  1.05013809e+01,  6.45556986e-01,\n",
       "        2.21011758e+00, -3.50617707e-01, -1.40276730e-01, -9.12284851e+00,\n",
       "       -8.45466971e-01, -1.47357357e+00, -5.99117756e-01, -1.20867691e+01,\n",
       "       -2.21914148e+00, -7.79105484e-01,  1.81045747e+00, -1.11778963e+00,\n",
       "       -6.83004022e-01,  2.29614592e+00, -2.07805586e+00, -2.55609214e-01,\n",
       "       -2.14334989e+00,  8.48770976e-01,  6.75324917e-01, -5.34638345e-01,\n",
       "       -6.48451686e-01,  3.45266533e+00,  1.27091265e+00, -3.97765040e-01,\n",
       "       -1.44706309e+00, -1.80432141e+00, -1.56298103e+01,  5.67612290e-01,\n",
       "        4.74841923e-01, -1.11156869e+00,  1.19026756e+00,  2.13323617e+00,\n",
       "        8.12425041e+00, -2.45696679e-01,  2.62245083e+00,  2.02101111e+00,\n",
       "        9.56128597e-01,  1.09419355e+01,  1.66287911e+00, -1.54963326e+00,\n",
       "       -4.44463938e-01,  3.44560099e+00,  1.82785630e+00,  6.85007763e+00,\n",
       "        1.47644363e+02, -2.72651887e+00,  8.75692844e+00,  4.76425934e+00,\n",
       "        6.33985043e-01, -1.83742118e+00, -9.07987404e+00, -1.70876741e+00,\n",
       "       -1.69649506e+00, -6.01110578e-01, -5.43950871e-02,  4.63609755e-01,\n",
       "       -1.41631782e+00, -1.73704255e+00,  6.12315130e+00, -1.36231232e+00,\n",
       "       -1.39677715e+00,  1.44102716e+00,  1.05859947e+00, -1.73258591e+00,\n",
       "       -2.59923309e-01,  3.21615744e+00,  5.49583149e+00, -4.46303272e+00,\n",
       "        2.50916910e+00, -3.58498335e-01,  2.30921888e+00,  1.70555162e+00,\n",
       "       -9.72156167e-01, -1.50439000e+00, -1.17256999e+00,  4.27761650e+00,\n",
       "       -2.44402599e+00, -1.63105512e+00, -1.31592703e+00,  1.07804928e+01,\n",
       "       -5.01864612e-01, -1.13192868e+00, -1.37049937e+00, -1.04088926e+01,\n",
       "        1.38692033e+00, -5.72608709e+00,  2.58949542e+00, -1.65545690e+00,\n",
       "        1.46428955e+00,  7.89074957e-01, -5.35210037e+00,  2.77717328e+00,\n",
       "       -6.33923709e-01, -6.20477676e-01,  8.95914137e-01,  5.98898220e+00,\n",
       "        9.33881342e-01, -2.57984906e-01,  1.33618760e+00, -1.46046340e+00,\n",
       "       -5.03324223e+00, -1.18451428e+00, -7.35996532e+00, -2.02642226e+00,\n",
       "       -4.51797247e-01,  2.10695052e+00,  2.51502872e+00, -9.89983654e+00,\n",
       "       -1.05243564e+00, -4.57521230e-02, -4.45155859e-01, -3.61895710e-01,\n",
       "       -4.14657593e-02,  8.42198730e-01,  1.45306501e+01,  9.78718567e+00,\n",
       "        3.27273637e-01, -4.18616712e-01, -3.14201880e+00, -2.30127484e-01,\n",
       "        1.21735084e+00, -1.70972371e+00,  2.29305339e+00, -2.38903093e+00,\n",
       "        2.09635764e-01, -2.55738378e-01, -5.96751094e-01, -2.24125171e+00,\n",
       "        3.92184585e-01,  2.57757640e+00,  3.73083234e+00,  1.51358593e+00,\n",
       "        1.08096981e+01, -1.58448629e-02, -3.32479447e-01, -1.38721895e+00,\n",
       "       -8.10899544e+00, -6.12826407e-01, -4.95109677e-01, -1.30568516e+00,\n",
       "       -9.61121845e+00, -2.35528207e+00,  2.01489472e+00,  1.07712460e+00,\n",
       "        1.05130517e+00, -1.16874623e+00,  6.84465468e-01,  2.01283264e+00,\n",
       "       -1.62603319e+00, -4.94826984e+00,  2.56619167e+00, -6.82257473e-01,\n",
       "        2.07690263e+00,  1.80129814e+00, -7.31643438e-01, -1.18480611e+00,\n",
       "       -1.65379715e+00, -1.13375425e+00,  1.37611961e+01, -4.30356383e-01,\n",
       "        4.03882936e-02, -7.39698052e-01,  2.03482962e+00, -3.17747116e-01,\n",
       "        1.09616852e+00,  7.05511522e+00, -1.90192437e+00, -1.00773084e+00,\n",
       "        1.84586036e+00, -8.06419373e-01, -2.00520253e+00,  1.43282980e-01,\n",
       "        8.24431241e-01,  4.22105503e+00, -1.77129567e+00,  8.68493915e-01,\n",
       "        2.78472137e+00,  1.28741121e+01,  6.52890146e-01, -3.27773333e-01,\n",
       "       -6.94489765e+00, -2.09843946e+00,  1.90716028e+00,  3.29520375e-01,\n",
       "       -6.48998737e-01, -1.19035375e+00,  1.47638428e+00,  2.68463135e-01,\n",
       "       -8.87290764e+00,  6.71646476e-01,  5.65553713e+00, -2.70009011e-01,\n",
       "        1.19868457e+00, -4.03371863e-02,  7.85024539e-02,  2.90104628e+00,\n",
       "        4.96084154e-01, -7.83662319e-01, -2.26295769e-01, -1.68725944e+00,\n",
       "        3.63061577e-01,  9.17901421e+00,  4.11496067e+00, -3.64474797e+00,\n",
       "        3.02400827e+00, -7.28832436e+00,  2.18834662e+00, -1.54012704e+00,\n",
       "       -8.94502044e-01,  1.04504013e+00,  3.69189239e+00,  4.30719227e-01,\n",
       "        2.35007906e+00, -2.90951824e+00,  2.73536062e+00, -2.76623547e-01,\n",
       "       -4.07518530e+00,  3.25626802e+00, -2.14447594e+00,  5.44106483e-01,\n",
       "        3.17319345e+00, -1.84183097e+00, -2.45009232e+00,  3.18471789e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec4[0]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000001, 0.9999978, 0.9999995967921089)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vec1*100, vec4*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 768)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13129687, 13130758, 13131323, 13131443, 13131871, 13132016,\n",
       "       13132089, 13132434, 13132436, 13132563, 13132882, 13133126,\n",
       "       13134870, 13134871, 13135081, 13135082, 13137759, 13138115,\n",
       "       13138216, 13138646, 13139260, 13140553, 13141684, 13142238,\n",
       "       13142715, 13143053, 13145024, 13145952, 13146640, 13148782,\n",
       "       13150721, 13150938, 13154038, 13155149, 13155360, 13155447,\n",
       "       13156462, 13156549, 13156550, 13158097, 13158838, 13159154,\n",
       "       13159445, 13160548, 13161249, 13161729, 13162690, 13162978,\n",
       "       13164578, 13164594, 13165673, 13165716, 13165725, 13165821,\n",
       "       13168172, 13169315, 13169448, 13171485, 13173832, 13174312,\n",
       "       13174413, 13175312, 13176306, 13176924, 13176987, 13177881,\n",
       "       13178438, 13178960, 13179431, 13179511, 13179580, 13179699,\n",
       "       13180148, 13180150, 13181141, 13181392, 13181673, 13181674,\n",
       "       13182573, 13183205, 13185089, 13186110, 13186111, 13186322,\n",
       "       13186457, 13186527, 13186582, 13186636, 13187134, 13187243,\n",
       "       13187733, 13188289, 13188839, 13190381, 13190592, 13190887,\n",
       "       13191728, 13192427, 13192953, 13194148, 13194295, 13195681,\n",
       "       13196338, 13196587, 13197919, 13198089, 13199062, 13199165,\n",
       "       13200031, 13200176, 13200928, 13201105, 13201168, 13201616,\n",
       "       13202115, 13202574, 13202790, 13203190, 13203526, 13203876,\n",
       "       13205035, 13205219, 13206281, 13207747, 13207778, 13208759,\n",
       "       13208798, 13208883, 13208907, 13209812, 13210226, 13210227,\n",
       "       13211240, 13211249, 13211667, 13211901, 13212214, 13212402,\n",
       "       13212576, 13212742, 13212902, 13216379, 13217285, 13217321,\n",
       "       13217547, 13218022, 13218119, 13218898, 13218915, 13219044,\n",
       "       13219232, 13219569, 13220487, 13220600, 13221477, 13221922,\n",
       "       13222836, 13223257, 13223505, 13223507, 13223523, 13225603,\n",
       "       13227033, 13227226, 13229219, 13229612, 13231643, 13232289,\n",
       "       13232348, 13232451, 13233199, 13233216, 13234738, 13235056,\n",
       "       13238901, 13238987, 13239398, 13239649, 13239899, 13239970,\n",
       "       13240527, 13240535, 13241408, 13242507, 13242617, 13243105,\n",
       "       13243106, 13243660, 13244218, 13244246, 13244522, 13245055,\n",
       "       13245937, 13246226, 13246720, 13248760, 13250660, 13251257,\n",
       "       13252148, 13252230, 13252269, 13253179, 13253192, 13253314,\n",
       "       13253410, 13253656, 13253802, 13253844, 13253932, 13254305,\n",
       "       13254309, 13254706, 13254880, 13254983, 13256278, 13256940,\n",
       "       13257285, 13258051, 13259794, 13259948, 13260937, 13261082,\n",
       "       13261483, 13261902, 13261912, 13261919, 13262206, 13262521,\n",
       "       13264046, 13264162, 13264594, 13265500, 13265662, 13267009,\n",
       "       13267164, 13267592, 13268090, 13268489, 13268632, 13269720,\n",
       "       13270076, 13272259, 13272652, 13273274, 13273307, 13273825,\n",
       "       13274220, 13274297, 13274353, 13275259, 13276210, 13278427,\n",
       "       13285808, 13285890, 13286104, 13287805, 13288309, 13288450,\n",
       "       13290159, 13291030, 13293049, 13295946, 13296229, 13297297,\n",
       "       13298863, 13299388, 13300231, 13301431, 13301439, 13303349,\n",
       "       13307904, 13307909, 13307933, 13307934, 13309781, 13309875,\n",
       "       13311700, 13311794, 13312407, 13312547, 13312548, 13312600,\n",
       "       13312653, 13313797, 13314319, 13314731, 13315082, 13315769,\n",
       "       13318244, 13318249, 13320267, 13320353, 13322032, 13322388,\n",
       "       13323725, 13324339, 13324538, 13325444, 13325445, 13326231,\n",
       "       13326338, 13326903, 13328229, 13329042, 13330656, 13334539,\n",
       "       13337329, 13337686, 13339536, 13344267, 13344728, 13346504,\n",
       "       13346505])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_bug_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = load_vector_from_file(\"vectorize_with_start_token_16_8\", project_name, 13285890)\n",
    "vec2 = load_vector_from_file(\"vectorize_with_start_token_16_8\", project_name, 13254983)\n",
    "\n",
    "vec3 = load_vector_from_file(\"vectorize_with_start_token_16_8\", project_name, 13241408)\n",
    "\n",
    "vec4 = load_vector_from_file(\"vectorize_with_start_token_16_8\", project_name, 13311794)\n",
    "\n",
    "vec5 = load_vector_from_file(\"vectorize_with_start_token_16_8\", project_name, 13288450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 16, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08097193,  0.36308792,  0.04277582, ..., -0.2115241 ,\n",
       "        -0.49770018,  0.31525454],\n",
       "       [-0.27197066,  0.5998293 ,  0.06930429, ...,  0.31632707,\n",
       "        -0.3551059 ,  0.4558832 ],\n",
       "       [-0.0881578 ,  0.33414343,  0.06369738, ..., -0.00215741,\n",
       "        -0.2014063 ,  0.19773135],\n",
       "       ...,\n",
       "       [ 0.396576  , -0.35732105,  0.31426805, ...,  0.3102206 ,\n",
       "        -0.53226924,  0.21116011],\n",
       "       [ 0.05698896,  0.18598104,  0.02964598, ...,  0.45809698,\n",
       "        -0.51010776,  0.17876989],\n",
       "       [-0.10310327, -0.0182554 ,  0.18384917, ..., -0.022183  ,\n",
       "        -0.6821444 ,  0.08129665]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002, 0.9999969, 0.9999995880006325)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vec1, vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99325293, 0.3726514, 0.7679155721589701)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec2, vec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = load_vector_from_file(\"vectorize_with_start_token_8_4\", project_name, 13285890)\n",
    "vec2 = load_vector_from_file(\"vectorize_with_start_token_8_4\", project_name, 13254983)\n",
    "\n",
    "vec3 = load_vector_from_file(\"vectorize_with_start_token_8_4\", project_name, 13241408)\n",
    "\n",
    "vec4 = load_vector_from_file(\"vectorize_with_start_token_8_4\", project_name, 13311794)\n",
    "\n",
    "vec5 = load_vector_from_file(\"vectorize_with_start_token_8_4\", project_name, 13288450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 768)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_find.are_dups(13285890, 13254983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9966876, 0.40570575, 0.7729556226870045)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_find.are_dups(13285890, 13241408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9971282, 0.49676418, 0.7758855856256559)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec1, vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9969356, 0.40055668, 0.7710841307369992)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec2, vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99489886, 0.6157195 , 0.5436915 , 0.6059772 , 0.6039168 ,\n",
       "        0.6595295 , 0.5686981 , 0.6254815 ],\n",
       "       [0.68428737, 0.8754417 , 0.7695261 , 0.87241226, 0.8385291 ,\n",
       "        0.87515545, 0.83551943, 0.8173313 ],\n",
       "       [0.69799685, 0.8631775 , 0.82252526, 0.881672  , 0.82135373,\n",
       "        0.8408125 , 0.87131333, 0.8136302 ],\n",
       "       [0.6863615 , 0.8595184 , 0.8516812 , 0.8961773 , 0.833771  ,\n",
       "        0.84667796, 0.8986519 , 0.85087335],\n",
       "       [0.5777862 , 0.8176497 , 0.8555644 , 0.8675926 , 0.79279816,\n",
       "        0.79086727, 0.8724389 , 0.817882  ],\n",
       "       [0.714564  , 0.8391959 , 0.8526437 , 0.873988  , 0.8044164 ,\n",
       "        0.81659514, 0.8741865 , 0.84333116],\n",
       "       [0.74942964, 0.8248822 , 0.7857038 , 0.8263962 , 0.8788897 ,\n",
       "        0.81393456, 0.81416285, 0.9148278 ],\n",
       "       [0.99490535, 0.61588514, 0.5438397 , 0.6061709 , 0.60406566,\n",
       "        0.65975434, 0.56889296, 0.6256654 ]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vec1[0], vec2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99327415, 0.6947002 , 0.7079872 , 0.6816975 , 0.68561506,\n",
       "        0.7371063 , 0.7442925 , 0.71217084],\n",
       "       [0.6505479 , 0.8219979 , 0.86206144, 0.8259842 , 0.8596764 ,\n",
       "        0.8586605 , 0.82494414, 0.8609283 ],\n",
       "       [0.5923667 , 0.8004302 , 0.8348173 , 0.8435491 , 0.8392767 ,\n",
       "        0.80725354, 0.7977699 , 0.825334  ],\n",
       "       [0.64112484, 0.8399166 , 0.87535673, 0.8427712 , 0.8798642 ,\n",
       "        0.8477106 , 0.8127351 , 0.8731103 ],\n",
       "       [0.63037837, 0.81454   , 0.8245261 , 0.7864444 , 0.800069  ,\n",
       "        0.89128304, 0.75679904, 0.82414806],\n",
       "       [0.6778821 , 0.8427292 , 0.8323697 , 0.7965471 , 0.8309359 ,\n",
       "        0.8321204 , 0.7832614 , 0.84668094],\n",
       "       [0.60807323, 0.8232173 , 0.8759638 , 0.85293627, 0.88856   ,\n",
       "        0.8232009 , 0.79783857, 0.85856354],\n",
       "       [0.65930545, 0.82077205, 0.84807837, 0.82547957, 0.8307118 ,\n",
       "        0.90097064, 0.7893821 , 0.83763397]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vec2[0], vec3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = load_vector_from_file(\"vectorize_with_start_token_1_1\", project_name, 13285890)\n",
    "vec2 = load_vector_from_file(\"vectorize_with_start_token_1_1\", project_name, 13254983)\n",
    "\n",
    "vec3 = load_vector_from_file(\"vectorize_with_start_token_1_1\", project_name, 13241408)\n",
    "\n",
    "vec4 = load_vector_from_file(\"vectorize_with_start_token_1_1\", project_name, 13311794)\n",
    "\n",
    "vec5 = load_vector_from_file(\"vectorize_with_start_token_1_1\", project_name, 13288450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1, 768)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002, 0.9999968, 0.9999995367128122)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002, 0.9999971, 0.9999996331002977)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec1, vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = load_vector_from_file(\"vectorize_with_start_token_64_48_1\", project_name, 13217285)\n",
    "vec2 = load_vector_from_file(\"vectorize_with_start_token_64_48_1\", project_name, 13155149)\n",
    "\n",
    "vec3 = load_vector_from_file(\"vectorize_with_start_token_64_48_1\", project_name, 13241408)\n",
    "\n",
    "vec4 = load_vector_from_file(\"vectorize_with_start_token_64_48_1\", project_name, 13311794)\n",
    "\n",
    "vec5 = load_vector_from_file(\"vectorize_with_start_token_64_48_1\", project_name, 13288450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 64, 768)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9942508, 0.12909682, 0.7255191441342379)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec2, vec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9928854, 0.07353795, 0.7371581824375862)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_find.are_dups(13241408, 13288450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9924883, 0.4346793, 0.7541349970609493)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec3, vec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13217285, 13155149]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_find.get_children(roots[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15073481,  0.5856519 ,  0.05962308, ..., -0.51702344,\n",
       "        -0.4738467 ,  0.36067766],\n",
       "       [-0.15038227,  0.586296  ,  0.05967231, ..., -0.51616377,\n",
       "        -0.47395954,  0.36051387],\n",
       "       [-0.01939514,  0.25956514,  0.2687979 , ..., -0.96655506,\n",
       "        -0.24458775,  0.02878243],\n",
       "       ...,\n",
       "       [-0.01939514,  0.25956514,  0.2687979 , ..., -0.96655506,\n",
       "        -0.24458775,  0.02878243],\n",
       "       [-0.01939514,  0.25956514,  0.2687979 , ..., -0.96655506,\n",
       "        -0.24458775,  0.02878243],\n",
       "       [-0.01939514,  0.25956514,  0.2687979 , ..., -0.96655506,\n",
       "        -0.24458775,  0.02878243]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11768337,  0.3209616 ,  0.03159433, ..., -0.27236986,\n",
       "        -0.5429191 ,  0.42362666],\n",
       "       [ 0.18198635,  0.14300252,  0.15753196, ..., -0.46674   ,\n",
       "        -0.58404803,  0.58083695],\n",
       "       [ 0.11711267,  0.25445563,  0.39045134, ...,  0.10765383,\n",
       "        -0.4396313 ,  0.55724216],\n",
       "       ...,\n",
       "       [-0.07054585, -0.03413796,  0.2433631 , ..., -0.9368543 ,\n",
       "        -0.17368065,  0.31552488],\n",
       "       [-0.07054585, -0.03413796,  0.2433631 , ..., -0.9368543 ,\n",
       "        -0.17368065,  0.31552488],\n",
       "       [-0.07054585, -0.03413796,  0.2433631 , ..., -0.9368543 ,\n",
       "        -0.17368065,  0.31552488]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = load_vector_from_file(\"vectorize_with_start_token_128_128_1\", project_name, 13217285)\n",
    "vec2 = load_vector_from_file(\"vectorize_with_start_token_128_128_1\", project_name, 13155149)\n",
    "\n",
    "vec3 = load_vector_from_file(\"vectorize_with_start_token_128_128_1\", project_name, 13241408)\n",
    "\n",
    "vec4 = load_vector_from_file(\"vectorize_with_start_token_128_128_1\", project_name, 13311794)\n",
    "\n",
    "vec5 = load_vector_from_file(\"vectorize_with_start_token_128_128_1\", project_name, 13288450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9928681, -0.007617988, 0.7235098232318813)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99370474, 0.09239145, 0.7202539981926572)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_3d(vec2, vec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 768)\n"
     ]
    }
   ],
   "source": [
    "desc1 = get_code_feature(conn, project_name, 13217285)\n",
    "text_index1 = tokenizer.encode(desc1[:1024],add_prefix_space=True)\n",
    "vector1 = model.transformer.wte.weight[text_index1,:].detach().numpy()\n",
    "print(vector1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 768)\n"
     ]
    }
   ],
   "source": [
    "desc2 = get_code_feature(conn, project_name, 13155149)\n",
    "text_index2 = tokenizer.encode(desc2[:1024],add_prefix_space=True)\n",
    "vector2 = model.transformer.wte.weight[text_index2,:].detach().numpy()\n",
    "print(vector2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02451675, -0.03975049,  0.06608102, ..., -0.09575277,\n",
       "        -0.07109229,  0.25476176],\n",
       "       [ 0.1582439 , -0.11231199,  0.0968036 , ..., -0.1165341 ,\n",
       "         0.05797191, -0.09210865],\n",
       "       [-0.0588978 , -0.14980642,  0.24618386, ...,  0.06663611,\n",
       "         0.10734763, -0.08830982],\n",
       "       ...,\n",
       "       [-0.12858012,  0.01429054,  0.07688746, ..., -0.10991439,\n",
       "         0.14854088,  0.19609007],\n",
       "       [-0.0141986 , -0.12260163,  0.02203064, ..., -0.00174358,\n",
       "         0.02886736,  0.0045931 ],\n",
       "       [ 0.10940462, -0.17140403,  0.18852605, ...,  0.22696522,\n",
       "         0.07817093,  0.0903419 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14709349,  0.00541914,  0.0007925 , ...,  0.01087318,\n",
       "        -0.06232191, -0.17451292],\n",
       "       [ 0.06138621, -0.01496532,  0.05657467, ..., -0.09185825,\n",
       "        -0.07350635, -0.08529535],\n",
       "       [ 0.16150954, -0.23382902, -0.00929563, ..., -0.02445086,\n",
       "         0.07281659, -0.12636934],\n",
       "       ...,\n",
       "       [ 0.19848964,  0.07959796,  0.25828296, ...,  0.08498395,\n",
       "         0.00151055,  0.02305836],\n",
       "       [-0.03283077, -0.13524216,  0.03931798, ..., -0.08220737,\n",
       "         0.08586881,  0.05019436],\n",
       "       [ 0.16900638, -0.1395443 ,  0.1761041 , ...,  0.17900853,\n",
       "        -0.14245942, -0.21913654]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000001, -0.0022347337, 0.26554371286914746)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 768)\n"
     ]
    }
   ],
   "source": [
    "desc5 = get_code_feature(conn, project_name, 13288450)\n",
    "text_index5 = tokenizer.encode(desc5[:1024],add_prefix_space=True)\n",
    "vector5 = model.transformer.wte.weight[text_index5,:].detach().numpy()\n",
    "print(vector5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000001, 0.015597839, 0.2765053069122)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vector2, vector5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000001, -0.0022347337, 0.2610943310569995)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score_2d(vector1, vector5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 768)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc1 = get_descriptions(conn, project_name, 13217285)\n",
    "text_index1 = tokenizer.encode(desc1[:1024],add_prefix_space=True)\n",
    "vector1 = model.transformer.wte.weight[text_index1,:].detach().numpy()\n",
    "print(vector1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipelines, AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 3.24k/3.24k [00:00<00:00, 1.28MB/s]\n",
      "Downloading: 100%|██████████| 660k/660k [00:00<00:00, 3.56MB/s]\n",
      "Downloading: 100%|██████████| 156/156 [00:00<00:00, 69.5kB/s]\n",
      "Downloading: 100%|██████████| 42.0/42.0 [00:00<00:00, 19.2kB/s]\n",
      "Downloading: 100%|██████████| 596M/596M [00:08<00:00, 72.4MB/s] \n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at jeniya/BERTOverflow and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jeniya/BERTOverflow\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"jeniya/BERTOverflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.cls_token] + tokenizer.tokenize(\"VScodeServer\") + [tokenizer.cls_token]\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_embeddings=model(torch.tensor(token_ids)[None,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8576, -0.9107, -0.8100,  0.2563, -0.1944, -0.5257, -0.3512,\n",
       "          -0.0875,  0.4532, -0.6161,  0.1918, -0.4659,  0.1670, -0.4333,\n",
       "           0.8217, -1.2933, -1.0150,  0.4772,  0.1306, -0.4730,  0.2298,\n",
       "          -0.0185,  0.2135,  0.5203, -0.6933,  0.5473,  0.2666, -0.0702,\n",
       "           0.6793, -0.9461, -0.3924, -0.7370, -0.2002,  0.9687,  0.0604,\n",
       "           0.4606,  0.7241,  0.0123,  0.5088,  0.4414, -0.5458, -0.5033,\n",
       "           0.4933,  0.6258,  0.1661,  0.5455,  0.2696, -0.0880, -0.6317,\n",
       "          -0.3873,  0.5481,  0.4491,  0.1527,  0.0201, -0.2823],\n",
       "         [-1.0158, -1.0748, -0.4443,  0.7127,  0.0449, -0.7537, -0.9474,\n",
       "          -0.6002,  0.1317, -0.3958,  0.6421, -0.8504,  0.5560,  0.1425,\n",
       "           0.7953, -0.1056, -0.4240,  1.1136,  0.4260, -0.4580, -0.0744,\n",
       "          -0.6878, -0.3053,  0.5217, -0.4050, -0.0263, -0.3445, -0.2196,\n",
       "           0.2806, -0.5976, -0.6152, -0.6020, -0.4007,  0.7480, -0.6538,\n",
       "           0.1980,  0.1268, -0.2855,  0.7026,  0.3072, -0.2806, -0.7506,\n",
       "           0.9004,  0.2521, -0.0173,  0.2761,  0.5152, -0.0060, -0.8371,\n",
       "          -0.3067, -0.0873, -0.2582, -0.3558, -0.5514,  0.1507],\n",
       "         [-0.8943, -1.0018, -0.6797, -0.2522, -0.1479, -1.2811, -0.4050,\n",
       "           0.1292, -0.1529,  0.0107,  0.3739, -0.0943,  0.2549,  0.3068,\n",
       "           1.0458, -0.9245, -0.5041,  0.2209,  0.5755, -0.1266, -0.0554,\n",
       "          -0.8136, -0.5131,  0.5728,  0.0149, -0.0203,  0.6649,  0.6554,\n",
       "           0.0655, -0.4499,  0.2331, -0.0734, -0.4930,  0.2905, -0.6506,\n",
       "           0.0900,  0.4534, -0.0847,  0.4363,  0.2594, -0.4076, -0.3625,\n",
       "           0.8569,  0.5086, -0.3876,  0.1187,  0.6530, -0.3440, -0.1471,\n",
       "          -0.6223,  0.1096,  0.1362,  0.0099, -0.7554,  0.4334]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
