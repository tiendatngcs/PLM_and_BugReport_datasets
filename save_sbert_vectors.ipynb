{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/t/tiendat.ng.cs/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "import sqlite3\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "import sys\n",
    "from itertools import combinations\n",
    "import random\n",
    "import json\n",
    "import my_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude stacktrace\n",
    "\n",
    "def remove_stacktrace(dataset):\n",
    "    desc_wo_stacktrace = []\n",
    "    for point in tqdm(dataset):\n",
    "        desc = point[\"description\"]\n",
    "        stacktraces = point[\"stacktrace\"]\n",
    "        for stacktrace in stacktraces:\n",
    "            desc = desc.replace(stacktrace[\"exception\"], \"\")\n",
    "            if stacktrace[\"message\"] is not None: desc = desc.replace(stacktrace[\"message\"], \"\")\n",
    "            if stacktrace[\"frames\"] is not None:\n",
    "                for frame in stacktrace[\"frames\"]:\n",
    "                    desc = desc.replace(frame[\"function\"], \"\")\n",
    "                    desc = desc.replace(frame[\"file\"], \"\")\n",
    "                    desc = desc.replace(str(frame[\"fileline\"]), \"\")\n",
    "        desc = desc.replace(\"\\tat \", \"\")\n",
    "        desc = desc.replace(\"at\\n\", \"\")\n",
    "        desc = desc.replace(\"(:)\", \"\")\n",
    "        desc = desc.split(\"\\n\\n\\n\\n\", 1)[0]\n",
    "        desc = desc.strip()\n",
    "        desc_wo_stacktrace.append(desc)\n",
    "    return desc_wo_stacktrace\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacktrace_as_string(point):\n",
    "    stacktraces = point[\"stacktrace\"]\n",
    "    ret = \"\"\n",
    "    for stacktrace in stacktraces:\n",
    "        ret += stacktrace[\"exception\"] + \" \"\n",
    "        if stacktrace[\"message\"] is not None: ret += stacktrace[\"message\"] + \" \"\n",
    "        if stacktrace[\"frames\"] is not None:\n",
    "            for frame in stacktrace[\"frames\"]:\n",
    "                ret += frame[\"function\"] + \" \"\n",
    "                if frame[\"file\"] is not None: ret += frame[\"file\"]\n",
    "                if frame[\"fileline\"] is not None: ret += \":\" + str(frame[\"fileline\"]) + \" \"\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicated_pairs(union_find):\n",
    "    roots = union_find.get_roots()\n",
    "    pairs = []\n",
    "    for root in tqdm(roots):\n",
    "        group = union_find.get_children(root)\n",
    "        pairs += list(combinations(group, 2))\n",
    "    for pair in tqdm(pairs):\n",
    "        assert(union_find.are_dups(pair[0], pair[1]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_duplicated_pairs(union_find, dataset, idx_to_bug_id, size):\n",
    "    from_dup = union_find.get_all_children()\n",
    "    #sample in some other single reports\n",
    "    assert(union_find.processed)\n",
    "    samples = random.sample(idx_to_bug_id, len(from_dup))\n",
    "    \n",
    "    pairs = []\n",
    "    count = 0\n",
    "    while (count < size):\n",
    "        pair = random.sample(samples, 2)\n",
    "        if pair[0] == pair[1] or union_find.are_dups(pair[0], pair[1]):\n",
    "            continue\n",
    "        pairs += [(pair[0], pair[1]),]\n",
    "        count += 1\n",
    "    for pair in tqdm(pairs):\n",
    "        assert(not union_find.are_dups(pair[0], pair[1]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is downloaded from https://zenodo.org/records/5746044#.Yej5HvtyZH6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_datasets = \"/home/grads/t/tiendat.ng.cs/github_repos/MLDatasets/EMSE_data\"\n",
    "\n",
    "projects = {\"campbell_dataset\" : \"campbell_stacktraces.json\", \n",
    "            \"eclipse_2018\" : \"eclipse_stacktraces.json\", \n",
    "            \"gnome_2011\" : \"gnome_stacktraces.json\", \n",
    "            \"netbeans_2016\" : \"netbeans_stacktraces.json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading netbeans 2016 dataset\n",
    "file_path = os.path.join(path_to_datasets, \"netbeans_2016\", projects[\"netbeans_2016\"])\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        dataset = json.load(json_file)\n",
    "    # print(dataset)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13703\n"
     ]
    }
   ],
   "source": [
    "num_br_withduplication = 0\n",
    "for point in dataset:\n",
    "    if point[\"dup_id\"] is not None:\n",
    "        num_br_withduplication += 1\n",
    "print(num_br_withduplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_bug_id = []\n",
    "for point in dataset:\n",
    "    idx_to_bug_id.append(point[\"bug_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_find = my_utils.UnionFind()\n",
    "union_find.process_json_data(dataset, \"netbeans_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6840"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union_find.get_roots())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 757/65417 [00:00<00:08, 7560.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65417/65417 [02:26<00:00, 445.68it/s] \n"
     ]
    }
   ],
   "source": [
    "descs_wo_stacktraces = remove_stacktrace(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the Windows Eastern European character encoding, and it is being used to load various resources. (The same problem exists in pre-Gandalf versions.) Presumably you set the encoding to this so\\n that you can load the _cs.properties files internally without hassle, but it is also the encoder that makes its way into the release builds. This converter is supported by the JDK and should be inclu\\nded in any port, but apparently the SGI JDK does not include full I18N support (maybe?) and one person had the following message on startup on Irix (SGI port of JDK 1.1.6):\\n\\njava.io.UnsupportedEncodingException\\n        at sun.io.ByteToCharConverter.getConverter(ByteToCharConverter.java:97)\\n\\n\\n        at java.io.InputStreamReader.<init>(InputStreamReader.java:82)\\n        at\\ncom.netbeans.developer.util.NetbeansBundle.createResourceBundleFromURL(NetbeansBundle.java:319)\\n\\n        at\\ncom.netbeans.developer.util.NetbeansBundle.findBundle(NetbeansBundle.java:294)\\n        at\\ncom.netbeans.developer.util.NetbeansBundle.getBundle(NetbeansBundle.java:258)\\n        at\\ncom.netbeans.developer.util.NetbeansBundle.getBundle(NetbeansBundle.java:235)\\n        at\\ncom.netbeans.developer.top.CoronaTopManager.<clinit>(CoronaTopManager.java:1321)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the Windows Eastern European character encoding, and it is being used to load various resources. (The same problem exists in pre-Gandalf versions.) Presumably you set the encoding to this so\\n that you can load the _cs.properties files internally without hassle, but it is also the encoder that makes its way into the release builds. This converter is supported by the JDK and should be inclu\\nded in any port, but apparently the SGI JDK does not include full I18N support (maybe?) and one person had the following message on startup on Irix (SGI port of JDK 1.1.6):\\n\\n\\n        at \\n\\n\\n        at'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs_wo_stacktraces[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retry sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save vector representation of short desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65417/65417 [12:17<00:00, 88.72it/s] \n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = point[\"short_desc\"]\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('netbeans_sbert_short_desc.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65417/65417 [01:23<00:00, 779.29it/s]\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.load('netbeans_sbert_short_desc.npz')\n",
    "\n",
    "short_desc_embeddings = []\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = str(point[\"bug_id\"])\n",
    "    short_desc_embeddings.append(loaded_data[bug_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vector representation of description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65417/65417 [31:11<00:00, 34.96it/s]   \n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = point[\"description\"]\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('netbeans_sbert_description.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vector representation of description wo stacktrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65417it [21:16, 51.23it/s]\n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point, desc_wo_stacktrace in tqdm(zip(dataset, descs_wo_stacktraces)):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = desc_wo_stacktrace\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('netbeans_sbert_description_wo_stacktrace.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vector representation of stacktrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java.lang.ArrayIndexOutOfBoundsException 1 >= 1 java.util.Vector.elementAt Vector.java:328 com.sun.java.swing.JTabbedPane.setIconAt JTabbedPane.java:772 com.netbeans.developer.base.windows.MultiObjectFrame.updateIcons MultiObjectFrame.java:336 com.netbeans.developer.base.windows.MultiObjectFrame.access$8 MultiObjectFrame.java:330 com.netbeans.developer.base.windows.MultiObjectFrame$5.propertyChange MultiObjectFrame.java:250 com.netbeans.developer.util.node.Node.fireOwnPropertyChange Node.java:280 com.netbeans.developer.util.node.Node.fireIconChange Node.java:213 com.netbeans.developerx.loaders.java.JavaNode.resolveIcons JavaNode.java:357 com.netbeans.developerx.loaders.java.JavaNode$3.run JavaNode.java:321 com.netbeans.developer.util.RequestProcessor$1.execute RequestProcessor.java:64 sunw.hotjava.misc.RequestProcessor.run RequestProcessor.java:130 java.lang.Thread.run Thread.java:474 '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stacktrace_as_string(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65417/65417 [44:23<00:00, 24.56it/s]  \n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = get_stacktrace_as_string(point)\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('netbeans_sbert_stacktrace.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save eclipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading netbeans 2016 dataset\n",
    "file_path = os.path.join(path_to_datasets, \"eclipse_2018\", projects[\"eclipse_2018\"])\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        dataset = json.load(json_file)\n",
    "    # print(dataset)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8332\n"
     ]
    }
   ],
   "source": [
    "num_br_withduplication = 0\n",
    "for point in dataset:\n",
    "    if point[\"dup_id\"] is not None:\n",
    "        num_br_withduplication += 1\n",
    "print(num_br_withduplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_bug_id = []\n",
    "for point in dataset:\n",
    "    idx_to_bug_id.append(point[\"bug_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_find = my_utils.UnionFind()\n",
    "union_find.process_json_data(dataset, \"eclipse_2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4297"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union_find.get_roots())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55968 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55968/55968 [00:25<00:00, 2219.44it/s]\n"
     ]
    }
   ],
   "source": [
    "descs_wo_stacktraces = remove_stacktrace(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) Create a resource that is the only resource in its folder.\\n2) Release this change to the cvs repository.\\n3) Delete the resource from your workspace.\\n4) Release this change to the cvs repository.  Note:  Because this was the only thing in the folder, th folder gets removed too.\\n5) Expand project versions to find the resource you want to add back in.\\n6) Select add to workspace.  Get an error dialog and a log entry:\\n\\nErrors adding project. \\nResource /org.eclipse.swt/ws/photon must exist.\\nAn internal error has occurred, consult the error log for details.\\n\\n(where /org.eclipse.swt/ws/photon was the folder my resource was in)\\n\\nLog: Mon Jun 04 09:20:28 EDT 2001\\n4 org.eclipse.vcm.ui 1 Errors adding project\\n\\t1=============<children>=============\\n\\t4 org.eclipse.core.resources 273 Could not delete: c:\\\\development\\\\target\\\\eclipse\\\\plugins\\\\Eclipse Launcher\\\\launcher_117.zip.\\n\\t1=============</children>=============\\nLog: Mon Jun 04 09:20:31 EDT 2001\\n4 org.eclipse.core.resources 273 Could not delete: c:\\\\development\\\\target\\\\eclipse\\\\plugins\\\\Eclipse Launcher\\\\launcher_117.zip.\\nLog: Mon Jun 04 11:40:53 EDT 2001\\n4 org.eclipse.vcm.core.cvs 4 Project version tag not found in history file\\nLog: Mon Jun 04 12:03:59 EDT 2001\\n4 org.eclipse.vcm.ui 1 Errors adding project\\n\\t1=============<children>=============\\n\\t4 org.eclipse.core.resources 368 Resource /org.eclipse.swt/ws/photon must exist.\\n\\t4 org.eclipse.vcm.ui 1 An internal error has occurred, consult the error log for details.\\njava.lang.NullPointerException\\n\\tat org.eclipse.core.internal.resources.SaveManager.sortTrees(SaveManager.java:981)\\n\\tat org.eclipse.core.internal.resources.SaveManager.collapseTrees(SaveManager.java:182)\\n\\tat org.eclipse.core.internal.resources.SaveManager.save(SaveManager.java:740)\\n\\tat org.eclipse.core.internal.resources.SaveManager.snapshotIfNeeded(SaveManager.java:881)\\n\\tat org.eclipse.core.internal.resources.Workspace.endOperation(Workspace.java:672)\\n\\tat org.eclipse.core.internal.resources.Workspace.run(Workspace.java:1188)\\n\\tat org.eclipse.ui.actions.WorkspaceModifyOperation.run(WorkspaceModifyOperation.java:78)\\n\\tat org.eclipse.jface.operation.ModalContext$ModalContextThread.run(ModalContext.java:98)\\n\\t1=============</children>=============\\n\\n\\nNOTES:\\n\\nVI (6/4/2001 12:13:45 PM)\\nI went and manually add the parent folder and then did \"Add to workspace\" and this worked.\\n\\n\\nKM (6/4/01 12:13:43 PM)\\n\\tThis I assume is a side effect that we are not auto-loading/creating parents when adding from workspace.\\n\\nCM (6/21/2001 11:02:18 AM)\\n\\tAnother way to reproduce this problem:\\n\\t- delete a package from a project  (package must have been versioned at one time)\\n\\t- go to repository, select deleted package, add to workspace (get error dialog)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) Create a resource that is the only resource in its folder.\\n2) Release this change to the cvs repository.\\n3) Delete the resource from your workspace.\\n4) Release this change to the cvs repository.  Note:  Because this was the only thing in the folder, th folder gets removed too.\\n5) Expand project versions to find the resource you want to add back in.\\n6) Select add to workspace.  Get an error dialog and a log entry:\\n\\nErrors adding project. \\nResource /org.eclipse.swt/ws/photon must exist.\\nAn internal error has occurred, consult the error log for details.\\n\\n(where /org.eclipse.swt/ws/photon was the folder my resource was in)\\n\\nLog: Mon Jun 04 09:20:28 EDT 2001\\n4 org.eclipse.vcm.ui 1 Errors adding project\\n\\t1=============<children>=============\\n\\t4 org.eclipse.core.resources 273 Could not delete: c:\\\\development\\\\target\\\\eclipse\\\\plugins\\\\Eclipse Launcher\\\\launcher_117.zip.\\n\\t1=============</children>=============\\nLog: Mon Jun 04 09:20:31 EDT 2001\\n4 org.eclipse.core.resources 273 Could not delete: c:\\\\development\\\\target\\\\eclipse\\\\plugins\\\\Eclipse Launcher\\\\launcher_117.zip.\\nLog: Mon Jun 04 11:40:53 EDT 2001\\n4 org.eclipse.vcm.core.cvs 4 Project version tag not found in history file\\nLog: Mon Jun 04 12:03:59 EDT 2001\\n4 org.eclipse.vcm.ui 1 Errors adding project\\n\\t1=============<children>=============\\n\\t4 org.eclipse.core.resources 368 Resource /org.eclipse.swt/ws/photon must exist.\\n\\t4 org.eclipse.vcm.ui 1 An internal error has occurred, consult the error log for details.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs_wo_stacktraces[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save vector representation of short desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55968/55968 [09:13<00:00, 101.21it/s]\n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = point[\"short_desc\"]\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('eclipse_sbert_short_desc.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vector representation of description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55968/55968 [29:25<00:00, 31.70it/s] \n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = point[\"description\"]\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('eclipse_sbert_description.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vector representation of description wo stacktrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55968it [17:30, 53.29it/s]\n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point, desc_wo_stacktrace in tqdm(zip(dataset, descs_wo_stacktraces)):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = desc_wo_stacktrace\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('eclipse_sbert_description_wo_stacktrace.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save vector representation of stacktrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java.lang.ArrayIndexOutOfBoundsException 1 >= 1 java.util.Vector.elementAt Vector.java:328 com.sun.java.swing.JTabbedPane.setIconAt JTabbedPane.java:772 com.netbeans.developer.base.windows.MultiObjectFrame.updateIcons MultiObjectFrame.java:336 com.netbeans.developer.base.windows.MultiObjectFrame.access$8 MultiObjectFrame.java:330 com.netbeans.developer.base.windows.MultiObjectFrame$5.propertyChange MultiObjectFrame.java:250 com.netbeans.developer.util.node.Node.fireOwnPropertyChange Node.java:280 com.netbeans.developer.util.node.Node.fireIconChange Node.java:213 com.netbeans.developerx.loaders.java.JavaNode.resolveIcons JavaNode.java:357 com.netbeans.developerx.loaders.java.JavaNode$3.run JavaNode.java:321 com.netbeans.developer.util.RequestProcessor$1.execute RequestProcessor.java:64 sunw.hotjava.misc.RequestProcessor.run RequestProcessor.java:130 java.lang.Thread.run Thread.java:474 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_stacktrace_as_string(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55968/55968 [27:45<00:00, 33.61it/s]  \n"
     ]
    }
   ],
   "source": [
    "data_to_save = {}\n",
    "for point in tqdm(dataset):\n",
    "    bug_id = point[\"bug_id\"]\n",
    "    sent = get_stacktrace_as_string(point)\n",
    "    sent_embedding = model.encode(sent,convert_to_tensor=True).numpy()\n",
    "    data_to_save[str(bug_id)] = sent_embedding\n",
    "\n",
    "np.savez('eclipse_sbert_stacktrace.npz', **data_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
