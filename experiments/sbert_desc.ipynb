{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/t/tiendat.ng.cs/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "import pynndescent\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../data_processing')\n",
    "sys.path.insert(0, '../datasets')\n",
    "import my_utils\n",
    "from ComponentAutoExtractor import ComponentAutoExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This experiment assert the how well sbert perform given only the short desc of BR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = \"/home/grads/t/tiendat.ng.cs/github_repos/PLM_and_BugReport_datasets\"\n",
    "data_path = os.path.join(home_path, \"datasets\", \"hand-gen-datasets\")\n",
    "\n",
    "# connect to db\n",
    "database_path = os.path.join(home_path, \"dbrd_processed.db\")\n",
    "conn = sqlite3.connect(database_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '/home/grads/t/tiendat.ng.cs/github_repos/PLM_and_BugReport_datasets/datasets/hand-gen-datasets/spark' already exists.\n",
      "Processing spark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9579/9579 [00:00<00:00, 84177.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bug_ids before filter:  9577\n",
      "Number of bug_ids after filter:  124\n"
     ]
    }
   ],
   "source": [
    "# process db table, create save folder\n",
    "table = \"spark\"\n",
    "save_path = os.path.join(data_path, table)\n",
    "my_utils.create_folder(save_path)\n",
    "\n",
    "union_find = my_utils.UnionFind()\n",
    "union_find.process_project(conn, table, min_desc_length=10)\n",
    "bug_ids = my_utils.get_bug_ids(conn, table)\n",
    "bug_ids_w_duplicates = union_find.get_all_children()\n",
    "\n",
    "# loop through each desc extract components, and save to file\n",
    "print(\"Number of bug_ids before filter: \", len(bug_ids))\n",
    "# remove bug_ids that are of very short desc and those that does not have log\n",
    "to_remove_ids = []\n",
    "for bug_id in bug_ids:\n",
    "    desc = my_utils.get_description(conn, table, bug_id)\n",
    "    # short_desc = my_utils.get_short_desc(conn, table, bug_id)\n",
    "    auto_extractor = ComponentAutoExtractor(desc)\n",
    "    if len(desc) < 50 or not auto_extractor.has_log() or bug_id not in bug_ids_w_duplicates:\n",
    "        to_remove_ids.append(bug_id)\n",
    "\n",
    "for to_remove_id in to_remove_ids:\n",
    "    bug_ids.remove(to_remove_id)\n",
    "\n",
    "print(\"Number of bug_ids after filter: \", len(bug_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 46070.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# finalize search space by adding duplicates of bug_ids_w_duplicates_and_stacktrace\n",
    "search_space = bug_ids.copy()\n",
    "for bug_id in tqdm(bug_ids):\n",
    "    dups = union_find.get_children(bug_id)\n",
    "    for dup in dups:\n",
    "        if dup != bug_id and dup not in search_space:\n",
    "            search_space.append(dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:05<00:00, 33.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert to vectors\n",
    "\n",
    "search_space_vects = {}\n",
    "for bug_id in tqdm(search_space):\n",
    "    desc = my_utils.get_description(conn, table, bug_id)\n",
    "    vect = model.encode(desc,convert_to_tensor=True).numpy()\n",
    "    search_space_vects[bug_id] = vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pynndescent.NNDescent(np.array(list(search_space_vects.values())), n_neighbors=50, metric=\"cosine\")\n",
    "index.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 874107.05it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Q_vects = []\n",
    "Q_indices = [search_space.index(bug_id) for bug_id in bug_ids]\n",
    "for bug_id in tqdm(bug_ids):\n",
    "    # eng = segregate_log_and_stacktrace(my_utils.get_descriptions(conn, table, bug_id))[0]\n",
    "    vect = search_space_vects[bug_id]\n",
    "    Q_vects.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = index.query(np.array(Q_vects), 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 30173.10it/s]\n"
     ]
    }
   ],
   "source": [
    "found_in_top_k_wo_stacktrace = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "for i in tqdm(range(len(bug_ids))):\n",
    "    q = bug_ids[i]\n",
    "    # print(\"Q = \", q)\n",
    "    # print(\"Index of query \", Q_indices[i])\n",
    "    # print(\"Index of neighbors \", neighbors[0][i])\n",
    "    # print(\"Duplicates \", union_find.get_children(q))\n",
    "    index_of_duplicates = [search_space.index(id) for id in union_find.get_children(q)]\n",
    "    # print(\"Index of duplicates \", index_of_duplicates)\n",
    "    for result_k in range(1, len(neighbors[0][i][:])):\n",
    "        if neighbors[0][i][result_k] in index_of_duplicates:\n",
    "            # increment from k to 10\n",
    "            for f in range(result_k, len(found_in_top_k_wo_stacktrace)):\n",
    "                found_in_top_k_wo_stacktrace[f] += 1\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.69354839, 0.71774194, 0.72580645, 0.75806452,\n",
       "       0.75806452, 0.77419355, 0.7983871 , 0.80645161, 0.80645161,\n",
       "       0.82258065])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_in_top_k_wo_stacktrace / len(bug_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 9, 129]\n",
      "[  9 129  12  94  21  18 126  86  38  44  67]\n"
     ]
    }
   ],
   "source": [
    "i = 9\n",
    "q = bug_ids[i]\n",
    "index_of_duplicates = [search_space.index(id) for id in union_find.get_children(q)]\n",
    "print(index_of_duplicates)\n",
    "print(neighbors[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool is whole table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
